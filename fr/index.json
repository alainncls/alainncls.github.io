[{"categories":null,"contents":" Le contexte Dans le cadre du lancement de son réseau de type ZK-EVM, Consensys a souhaité organiser un événement pour inviter un maximum d’utilisateurs à interagir avec le réseau. En effet, il s’agissait à la fois de faire connaitre celui-ci, et de tester sa capacité à supporter un grand nombre d’utilisateurs.\nMais pour faire venir un grand nombre de testeurs, il fallait leur donner une raison de venir. C’est pourquoi, lors du \u0026#34;Testnet Voyage\u0026#34;, Consensys a choisi de compter sur des applications autour de la DeFi, mais aussi de l’identité avec le protocole ENS, ou encore le protocole Lens pour l’aspect social.\nL’application C’est ainsi qu’est née l’idée de \u0026#34;Lineaster\u0026#34;, un fork de Lenster, désormais renommé en \u0026#34;Hey.xyz\u0026#34;. Le protocole Lens n’étant déployé que sur Polygon, il fallait tout d’abord déployer sa stack technique sur Linea. Nous avons bénéficié du travail de l’équipe de Lens pour ce faire.\nEn parallèle, le projet consistait à adapter le client web Lenster aux protocoles disponibles ou non sur Linea. C’est ainsi qu’il a fallu trouver une nouvelle plateforme de NFT pour afficher les tokens possédés par les utilisateurs, ou encore nous passer de OpenZeppelin Defender qui n’était pas encoré déployé sur Linea à ce moment-là.\nLe résultat Une fois mise en ligne, l’application a immédiatement été utilisée dans le cadre du \u0026#34;Testnet Voyage\u0026#34;, et a permis à de nombreux utilisateurs de découvrir le protocole Lens, et de tester le réseau Linea.\nDe manière à limiter l’impact des bots qui ont pu être utilisés pour spammer le réseau, nous avons mis en place une règle simple : pour créer un profil Lens sur Linea, il fallait avoir au préalable créé un profil ENS sur Linea.\nAu final, les chiffres ont dépassé nos espoirs, avec :\n270 000 domaines ENS créés (cf. Lineascan)\n195 000 noms Lens créés (cf. Lineascan)\n191 000 profils Lineaster créés\nDe plus, comme la quête Linea impliquait d’utiliser le protocole et le client web mis en place, cela a généré un engagement massif avec les différentes fonctionnalités mises à disposition :\n150 000 posts créés\n7 000 posts re-partagés\n9 000 commentaires\n90 000 posts collectés\n100 000 follows\nLa stack technique Côté front React\nWeb3 Lens Protocol, Infura, Linea, Solidity\nOutils GitHub\n","permalink":"https://alainnicolas.fr/fr/projects/lineaster/","tags":["TypeScript","React","Ethereum","Lens","Linea","Solidity"],"title":"Lineaster"},{"categories":null,"contents":" Le client Pour des raisons de confidentialité, le nom de ce client ne peut pas être révélé. Il s’agit d’une entreprise déjà largement installée dans le domaine du web3, souhaitant étendre sa portée.\nLe projet Le projet consiste en la création d’une plateforme centralisée de prêt de cryptomonnaies, contre un collatéral fourni par les utilisateurs.\nIl fallait donc créer une interface utilisateur suffisamment compréhensible et claire pour attirer le plus grand nombre, mais aussi fournir toutes les fonctionnalités standards dans ce type d’application. Cette interface se décline aussi en une version \u0026#34;administrateur\u0026#34; pour paramétrer les cryptomonnaies disponibles en tant que collatéral ou à emprunter, les offres de prêts du moment, etc.\nDans la mesure où la plateforme est centralisée, elle ne repose pas sur des smart contracts, mais sur un backend capable de gérer les emprunts, les profils utilisateurs, etc.\nLa stack technique Côté front React\nCôté back TypeScript (NestJS)\nBase de données PostgreSQL\nWeb3 Infura, Bitcoin, Ethereum, ERC-20, Consensys Codefi Orchestrate\nOutils GitHub, GitHub Actions, SonarQube, Docker, Kubernetes\n","permalink":"https://alainnicolas.fr/fr/projects/crypto-lending/","tags":["TypeScript","NestJS","React","Docker","PostgreSQL","Bitcoin","Ethereum","ERC-20","Infura"],"title":"Plateforme de prêt de cryptomonnaies"},{"categories":null,"contents":" Le contexte Création de ce site pour me présenter et partager mes passions.\nMa première envie était de pouvoir montrer mes compétences de manière plus maîtrisée que sur LinkedIn par exemple. De même, de manière à centraliser efficacement les articles que j’ai pu rédiger sur Medium ou le blog de Talan Labs, il me fallait un blog.\nLa solution technique L’outil Ce site est conçu grâce à un générateur de site statique, Hugo, et hébergé gratuitement grâce au service \u0026#34;GitHub Pages\u0026#34;.\nLe thème Partir d’une page vierge n’étant ni aisé ni particulièrement motivant pour un projet personnel, j’ai choisi de partir d’un thème. En effet, le site d’Hugo présente de nombreux thèmes. C’est ainsi que j’ai retenu celui développé par Eddie Webbinaro : hugo resume.\nL’hébergement Ce site est hébergé grâce au service gratuit GitHub Pages.\n","permalink":"https://alainnicolas.fr/fr/projects/ce-site/","tags":["Perso","Hugo","Tarteaucitron","Insights"],"title":"Ce site"},{"categories":null,"contents":" Le contexte Création d’un blog pour ma compagne, afin de partager sa passion pour le tricot et la couture.\nLa solution technique La première version La première version du site utilisait Ghost, une solution de blogging complète concurrente de WordPress. Basé sur un outil open-source et gratuit, le blog était hébergé sur une petite machine AWS.\nLa seconde version En janvier 2021 j’ai fait le choix de basculer vers un générateur de site statique, Hugo, afin de pouvoir héberger gratuitement les pages générées.\nLe blog est ainsi déployé et hébergé grâce au service gratuit GitHub Pages.\n","permalink":"https://alainnicolas.fr/fr/projects/roxthecasbah/","tags":["Perso","Hugo","Insights"],"title":"RoxTheCasbah"},{"categories":null,"contents":" Le contexte Création du site vitrine du salon de coiffure \u0026#34;Atelier 58\u0026#34; à Paris.\nLa solution technique L’outil Ce site est conçu grâce à un générateur de site statique, Hugo.\nIntégration du service Planity pour la prise de rendez-vous.\nMise en place d’un suivi des statistiques de navigation via Insights.\nLe thème Afin de gagner du temps, mais aussi de répondre au mieux aux besoins d’un tel commerce, je suis parti du thème \u0026#34;Hugo Hero Theme\u0026#34;.\nL’hébergement Ce site est hébergé via Netlify.\n","permalink":"https://alainnicolas.fr/fr/projects/atelier-58/","tags":["Perso","Hugo","Insights"],"title":"Atelier 58"},{"categories":null,"contents":" Le contexte Maintenance du blog de Talan Labs, rédaction d’articles, avant une refonte complète en 2019/2020.\nLe blog des Labs de Talan permet de partager les connaissances des collaborateurs de Talan Labs.\nLa solution technique La version \u0026#34;legacy\u0026#34; La première version du site utilisait WordPress, solution qu’il n’est plus nécessaire de présenter.\nLa refonte Face à la difficulté de maintenir à jour un tel site, tout en garantissant sa sécurité, nous avons choisi de changer radicalement de technologie afin de réduire considérablement la surface d’attaque.\nEn basculant vers un générateur de site statique, Hugo, les pages HTML générées sont déployées et hébergées gratuitement via le service GitHub Pages.\nDe manière à rendre le blog conforme au RGPD, j’ai eu l’occasion de mettre en place l’outil tarteaucitron qui gère le consentement des visiteurs quant aux cookies utilisés par le site (Google Analytics et Disqus).\n","permalink":"https://alainnicolas.fr/fr/projects/talan-blog-labs/","tags":["Hugo","WordPress","Tarteaucitron"],"title":"Blog des Labs de Talan"},{"categories":null,"contents":" Le client En tant qu’acteur majeur du secteur bancaire, BNP Paribas se doit de rester à la pointe des technologies disponibles. C’est ainsi que les technologies blockchain et DLT se sont imposées comme incontournables.\nComme de nombreuses grandes entreprises, la BNP est découpée en plusieurs entités qui peuvent toutes participer à un même projet, ce qui n’est pas sans soulever des challenges autour de la collaboration.\nLe projet Pour permettre à toutes les entités de la BNP d’expérimenter sur la blockchain avant de facilement rejoindre un consortium décentralisé, il fallait rendre accessible des technologies que nous pouvons qualifier d’exotiques.\nC’est ainsi que notre challenge était de rendre possible la création en 1 clic de réseaux entiers de nœuds dans un environnement cloud.\nLa stack technique Les Blockchain \u0026amp; DLT Les technologies retenues par la BNP que nous devions rendre accessibles :\nCorda Enterprise\nHyperledger Fabric\nQuorum\nL’environnement technique Conteneurisation avec Docker, nombreux scripts Shell et automatisation des installations avec Ansible.\n","permalink":"https://alainnicolas.fr/fr/projects/bnp-blockchain/","tags":["Kanban","Docker","Corda","Quorum","Hyperledger Fabric","Shell"],"title":"BNP CIB - Blockchain-as-a-Service"},{"categories":null,"contents":" Le client Coface est un acteur majeur de l’assurance-crédit. De manière à toujours rester compétitif et gagner de nouvelles parts de marchés, l’entreprise a besoin de proposer régulièrement de nouveaux produits et solutions logicielles à ses clients.\nLe projet Optimisation et évolution d’une application web (Cofanet Policy Master \u0026amp; Cofanet Policy Master Administration) à destination de clients payants.\nPour cela, il fallait envisager un refactoring technique de l’architecture projet et la refonte des fonctionnalités majeures de l’application.\nDe plus, au-delà des aspects techniques, j’ai eu la chance de pouvoir accompagner le passage en mode Agile (Scrum) sur l’ensemble du projet, mais aussi peser dans les décisions de design à mettre en place.\nLa stack technique Côté client JavaScript, HTML5, CSS3, jQuery, Ajax, Bootstrap\nCôté back Service Spring / Spring MVC basé sur Java 6 avant une migration vers Java 8\nBase de données OracleDB\n","permalink":"https://alainnicolas.fr/fr/projects/coface/","tags":["Scrum","Spring MVC","Java","JSP","OracleDB","jQuery"],"title":"Coface"},{"categories":null,"contents":" Le client e-Paye édite des logiciels dédiés au SIRH : paie, coffre-fort numérique, gestion des RH, gestion des entretiens, etc.\nLe projet Parmi les modules d’e-Paye, celui permettant la génération des fiches de paye est particulièrement important et complexe. En effet, il doit prendre en compte la législation parfois changeante, mais aussi être capable de générer un grand nombre de fiches de paye en une durée restreinte.\nLa stack technique Côté client JavaScript, HTML5, CSS3, jQuery, Ajax\nCôté back Spring (Core, MVC, Security, Data)\nJava 8\n","permalink":"https://alainnicolas.fr/fr/projects/epaye/","tags":["Scrum","Spring MVC","Java","JSP","mySQL"],"title":"e-Paye"},{"categories":null,"contents":" Le client La Direction Numérique d’EDF Commerce a une équipe dédiée à la réalisation de PoC pour l’ensemble des métiers du groupe.\nLa mission La mission consiste à évangéliser sur les notions de craftsmanship et industrialiser les bonnes pratiques à mettre en place. C’est ainsi que j’ai pu initier la mise en place des premiers pipelines CI/CD via Gitlab et Jenkins, mais aussi pousser l’utilisation de SonarQube pour le suivi de qualité du code ou celle de Nexus pour y déposer les artefacts générés.\nÀ titre d’exemple, j’ai eu l’occasion de créer un micro-service Spring Boot capable de déposer des fichiers qu’il chiffre dans un bucket S3 on-premises avec récupération des clés dans un Vault, tout en proposant différents niveaux de tests automatisés.\nLa stack technique Côté front Vue.js (basé sur Nuxt)\nCôté back Java (Restlet / Spring Boot) et Node.js Hashicorp Vault, SDK AWS (S3 hébergé on premises)\nBase de données PostgreSQL, MongoDB\nOutils Gitlab, Jenkins, SonarQube, Docker, OpenShift\n","permalink":"https://alainnicolas.fr/fr/projects/edf/","tags":["Spring Boot","Java","Vue.js","Docker","Spring REST Docs","Vault","Gitlab","SonarQube"],"title":"EDF Commerce - Évangélisation craftsmanship"},{"categories":null,"contents":" Le client Éditeur de logiciels dédiés à la gestion de la supply chain, FuturMaster a fait appel à Talan Labs pour renforcer ses équipes de développement et accélérer la refonte de sa suite d’outils.\nLe projet C’est ainsi que j’ai fait partie de la première squad agile, composée de 3 développeurs, 1 designer et 1 Scrum Master. Nous étions chargés de la refonte du module Calibrate Model qui vise à afficher l’historique de vente d’un produit et la simulation de ses ventes futures.\nLa stack technique Côté front Application React, avec mise en place d’un découpage en micro-frontend grâce à la librairie Lerna.\nCôté back Service Spring Boot basé sur Java 11, avec Spring Data pour accéder aux données.\nBase de données MongoDB\n","permalink":"https://alainnicolas.fr/fr/projects/futurmaster-calibrate-model/","tags":["Scrum","Spring Boot","Java","React","MongoDB","Docker","Spring REST Docs","SonarQube"],"title":"FuturMaster - Calibrate Model"},{"categories":null,"contents":" Le client Éditeur de logiciels dédiés à la gestion de la supply chain, FuturMaster a fait appel à Talan Labs pour renforcer ses équipes de développement et accélérer la refonte de sa suite d’outils.\nLe projet Suite au succès de l’intervention de la première squad de Talan Labs chez FuturMaster sur le projet Calibrate Model, nous nous sommes lancés dans la refonte du module Master Data, chargé de centraliser le référentiel de données qui alimentent les autres modules de la suite logicielle.\nEn parallèle du développement de user stories fonctionnelles, de vastes sujets techniques s’offrent à nous, comme une réflexion autour de la future base de données la plus adaptée aux spécificités des objets à manipuler.\nLa stack technique Côté front Application React, découpée en micro-frontend. Utilisation des \u0026#34;hooks\u0026#34; introduits dans la version 16.8 de React.\nCôté back Service Spring Boot basé sur Java 11, avec Spring Data pour accéder aux données.\nBase de données OracleDB\n","permalink":"https://alainnicolas.fr/fr/projects/futurmaster-master-data/","tags":["Scrum","Spring Boot","Java","React","MongoDB","Docker","Spring REST Docs","SonarQube"],"title":"FuturMaster - Master Data"},{"categories":null,"contents":" Le client Gefco est un acteur incontournable de la logistique et notamment du transport de pièces automobiles.\nLe projet Développement d’un système de génération de plannings sous contraintes.\nLa stack technique Client lourd Java Swing\nBase de données OracleDB\n","permalink":"https://alainnicolas.fr/fr/projects/gefco/","tags":["Cycle en V","Java","Java Swing","OracleDB"],"title":"Gefco - Opteam"},{"categories":null,"contents":" Le contexte Share2Gether, vise à créer une solution d’organisation d’événements, à l’image de ce que propose Meetup.com.\nJ’ai eu l’occasion de partager plus en détails cette expérience dans un article dédié.\nLa stack technique Côté client Le front est une application Vue.js qui communique avec les smart-contracts déployés sur la blockchain grâce à la librairie web3.js.\nCôté blockchain Les smart-contracts écrits en Solidity sont déployés sur une blockchain Ethereum. Utilisation des contrats standards fournis par OpenZeppelin.\n","permalink":"https://alainnicolas.fr/fr/projects/share2gether/","tags":["Scrum","Blockchain","Ethereum","Vue.js","Node.js","Gitlab"],"title":"Share2gether"},{"categories":null,"contents":" Le contexte Comme toutes les entreprises, Talan cherche à catalyser la collaboration en son sein. De plus, Talan souhaite renforcer son unité en tant que groupe malgré des entités distinctes et une répartition sur 4 continents et développer une horizontalité bien loin des hiérarchies verticales classiques.\nUne monnaie interne, commune à tous les collaborateurs, peu importe leur localisation ou leur rôle hiérarchique, permet de trouver un point commun entre tous les acteurs de l’entreprise. C’est aussi une manière de permettre à tous de mieux échanger, y compris entre équipes distinctes, affirmant ainsi une hiérarchie horizontale.\nPlus de détails dans l’article que j’ai dédié à Talan Coin.\nLa stack technique Côté client Application iOS native\nApplication Android native\nApplications web Angular :\nDashboard de suivi statistique et d’administration\nBoutique d’objets et services payables en Talan Coins\nClient desktop (non mis en production)\nCôté back Services Spring Boot basés sur Java 8, servant d’interface entre la blockchain et les clients mobiles.\nBlockchain Ethereum avec un consensus PoA (Clique) et des smart contracts en Solidity.\nBase de données MongoDB pour stocker les transactions et y accéder plus rapidement. Reconstructible à partir des données stockées sur la blockchain.\n","permalink":"https://alainnicolas.fr/fr/projects/talan-talancoin/","tags":["Kanban","Spring Boot","Java","Ethereum","Solidity","MongoDB","Android","iOS","Angular","Docker"],"title":"Talan Coin"},{"categories":null,"contents":" Le contexte Après le succès de Talan Coin, le groupe VINCI a souhaité expérimenter avec sa propre version de l’application.\nC’est ainsi que nous avons instancié l’application VCoin, avec quelques spécificités la démarquant de Talan Coin.\nLa stack technique Côté client Application iOS native\nApplication Android native\nApplications web Angular :\nDashboard de suivi statistique et d’administration\nBoutique d’objets et services payables en Talan Coins\nClient desktop (non mis en production)\nCôté back Services Spring Boot basés sur Java 8, servant d’interface entre la blockchain et les clients mobiles.\nBlockchain Ethereum avec un consensus PoA (Clique) et des smart contracts en Solidity.\nBase de données MongoDB pour stocker les transactions et y accéder plus rapidement. Reconstructible à partir des données stockées sur la blockchain.\n","permalink":"https://alainnicolas.fr/fr/projects/vct-vcoin/","tags":["Kanban","Spring Boot","Java","Ethereum","Solidity","MongoDB","Android","iOS","Angular","Docker"],"title":"VINCI Construction Terrassement - VCoin"},{"categories":null,"contents":" Vous codez pour le travail, mais aussi dans votre vie perso ? Sur le même ordinateur ? Alors il est probable que vous vous retrouviez régulièrement avec des commits utilisant votre adresse mail perso sur vos projets pro, et vice-versa.\nEt c’est énervant, n’est-ce pas ? Sans arrêt à devoir réécrire l’historique d’un côté, de l’autre, avec des commits entérinés pour de bon sur une branche main protégée, etc.\nIl est temps que cela cesse ! Je vous propose donc de mieux paramétrer vos environnements Git. Pour cela, deux approches possibles.\n1. Repository par repository C’est bien sûr la technique qui apporte la granularité la plus fine. Vous pouvez en effet surcharger les réglages Git globaux projet par projet, via les commandes suivantes, à exécuter à la racine de chaque projet :\ngit config user.name \u0026#34;Nom Pro\u0026#34; git config user.email \u0026#34;pro@corporate.com\u0026#34; 2. Répertoire par répertoire Cette fois-ci il s’agit de séparer plus drastiquement vos projets, pour gagner un temps précieux :\nDans votre configuration globale (probablement ~/.gitconfig), saisissez les \u0026#39;name\u0026#39; et \u0026#39;email\u0026#39; que vous avez le plus de chance d’utiliser en priorité, disons vos informations pro\nAjoutez les 2 lignes suivantes après ces informations pour les surcharger de manière conditionnelle (ici, uniquement si l’on se trouve dans le répertoire ~/Perso) :\n[includeIf \u0026#34;gitdir:~/Perso/\u0026#34;] path = ~/Perso/.gitconfig Dans ~/Perso, ajoutez un fichier .gitconfig qui contiendra cette fois-ci vos informations perso\nLorsque vous travaillerez dans le dossier ~/Perso, vos commits porteront automatiquement vos informations perso, fini les prises de tête !\nEt pour les projets qui ont déjà des commits mélangés ? Et si malgré tout vous avez des repositories qui mélangent des commits avec vos informations pro et perso, vous pouvez toujours passer par la technique que je décrivais dans cet article pour faire le ménage !\n","permalink":"https://alainnicolas.fr/fr/blog/gerez-double-vie-git/","tags":["Git","GitHub"],"title":"Gérez votre double vie sur Git !"},{"categories":null,"contents":" Vous aussi, vous avez des dizaines de projets JavaScript/TypeScript enfouis dans des dossiers plus ou moins bien rangés sur votre ordinateur ? Vous savez, ces projets perso abandonnés après le premier commit et les projets pro terminés de longue date…​\nEt dans le même temps, vous voyez votre disque dur se remplir ? Bah oui, npm a la mauvaise habitude de télécharger la moitié d’internet à chaque installation…​\nVoici la solution pour faire de la place sans se prendre la tête et en conservant votre projet d’application révolutionnaire qui a à peine démarré. Il y a 4 ans.\nL\u0026#39;état de votre disque dur après 4 ans de `npm install`\rnpkill est un outil open-source qui vous permet de supprimer rapidement et facilement les répertoires node_modules qui encombrent votre ordinateur.\nPour cela, rien de plus simple, lancez npx npkill n’importe où sur votre ordinateur et il va chercher tous les répertoires node_modules.\nIl vous présente la liste avec la taille de chacun de ces répertoires et vous pouvez alors choisir de les supprimer ou de les conserver. Et le résultat final est souvent très satisfaisant, avec potentiellement plusieurs gigaoctets d’espace libéré !\nRetrouvez toutes les options de cet outil sur sa documentation !\n","permalink":"https://alainnicolas.fr/fr/blog/npkill-liberez-espace/","tags":["NPM"],"title":"Faites de la place avec npkill"},{"categories":null,"contents":" Le contexte La gestion des dépendances est un aspect primordial de tout projet. Dans le monde de Node.js, npm est l’outil standard pour installer et gérer les dépendances, mais n’oublions pas ses cousins yarn ou encore pnpm. Le fichier package.json liste toutes les dépendances et leurs versions.\nLorsque l’on travaille sur un projet en équipe, il est important que le fichier package.json soit maintenu de manière cohérente. Et c’est là que le package sort-package-json entre en jeu.\nsort-package-json Il permet de trier le fichier package.json par ordre alphabétique selon les noms de packages. Cela permet évidemment de maintenir une cohérence dans l’ordre des dépendances, facilitant ainsi la lecture et la maintenance du fichier.\nAu-delà des dépendances, qui sont triées par défaut si vous n’avez fait que des installations en ligne de commande (npm install XXX), sort-package-json va aussi trier les autres champs du fichier, comme l’auteur, le nom du projet, sa version, etc.\nPour cela, ce package utilise des règles définies ici.\nSon utilisation Pour l’utiliser, rien de plus simple ! Un simple npx sort-package-json et le tour est joué !\nMais vous pouvez aussi l’intégrer à une stratégie plus large de standardisation sur votre projet, par exemple en l’ajoutant aux tâches exécutées par vos hooks Git avec Husky, comme décrit dans la documentation ici.\n","permalink":"https://alainnicolas.fr/fr/blog/triez-vos-dependances/","tags":["Nodejs","NPM"],"title":"Triez vos dépendances !"},{"categories":null,"contents":" Maintenant que votre blog est en ligne et que vous arrivez à vous motiver pour rédiger des articles, il est temps de le faire un peu décoller. Quoi qu’on en dise, avoir des lecteurs, voire des retours (positifs si possible), ça flatte l’ego, et ça encourage à en faire plus, à s’améliorer. Sans pour autant perdre de vue que votre blog est avant tout VOTRE blog.\nConsidérer qu’un post est un pense-bête Je trouve que c’est un excellent moyen de s’approprier son blog tout en accélérant la cadence de publication : à chaque fois que l’on apprend quelque chose, on devrait en tirer un post. Votre blog devient alors une extension de votre cerveau, pour noter tout ce que vous n’arrivez jamais à retenir.\nPar exemple, si vous cherchez très régulièrement \u0026#34;Comment centrer une div en CSS\u0026#34;, il serait peut-être temps de le noter sur votre site, la réponse viendra toujours plus rapidement. Et peut-être même que vous retiendrez la solution au passage !\nIdem avec les commandes que vous oubliez tout le temps. Quel est l’ordre des paramètres de la commande cp déjà ? Bref, vous avez compris mon point : vous pouvez transformer votre blog en une sorte de liste de pense-bêtes. Attention à ne pas arrêter totalement les articles plus approfondis qui attirent une autre typologie de lecteurs.\nDans tous les cas, c’est un très bon moyen de combattre le manque d’inspiration, de tenir le rythme que vous vous êtes fixé, mais aussi de conserver votre référencement en mettant régulièrement à jour votre site !\nLier article(s) et repository GitHub Vous rédigez un article technique et vous écrivez des bouts de code au milieu ? Pourquoi ne pas aller un cran plus loin en créant un projet de démonstration ?\nL’objectif est double : montrer des choses réelles, qui fonctionnent, mais aussi se constituer un petit portfolio public pour exposer ce que l’on sait faire. De mon côté, j’estime que le développement de ce projet fait partie de ma (longue) phase de réflexion, donc j’ai tendance à coder avant de rédiger l’article. Mais évidemment, en cours de rédaction, il vient toujours un moment où l’on se rend compte qu\u0026#34;il faudrait améliorer le code, donc on y revient.\nEn partant de votre cas d’usage ou de la démonstration technique que vous faites, il devient plus facile d’illustrer de manière très concrète votre article. Je pense d’ailleurs que c’est le moyen le plus facile de rédiger un article très technique. On y gagne au passage l’assurance que le code montré est vraiment fonctionnel, ce qui n’est pas toujours le cas lorsque l’on pioche aveuglément du code entre deux paragraphes de texte.\nMulti-poster Il est intéressant de multiplier les supports pour toucher un public plus large. Vous pouvez poster votre article sur votre blog perso, mais aussi sur le blog de votre entreprise, sur Medium ou encore LinkedIn.\nDans tous les cas, n’oubliez pas de spécifier une URL canonique pour éviter tout problème de \u0026#34;duplicate content\u0026#34;, autrement dit une pénalisation SEO de la part des indexers qui estimeraient que vous ne faites que copier du contenu externe.\nEt, évidemment, partagez votre article sur les réseaux sociaux pour toucher encore plus de monde et ramener du trafic sur votre page !\nCet article conclut une série sur la tenue d’un blog, de la mise en place technique du site jusqu’aux techniques de rédaction pour le faire vivre. Qu’en avez-vous pensé ? Y a-t-il d’autres points à aborder ? N’hésitez pas à m’envoyer un mail ou un message sur LinkedIn pour en parler !\n","permalink":"https://alainnicolas.fr/fr/blog/blog-it-yourself-aller-plus-loin/","tags":["Blogging"],"title":"Blog It Yourself - Aller plus loin"},{"categories":null,"contents":" Nous l’avons vu dans l’article précédent, les blocages sont nombreux pour nous empêcher de rédiger des articles. Je vous partage ici mon expérience pour les combattre.\nEssayons de voir comment surmonter la paralysie de la page blanche pour un développeur ! Et combattons le syndrome de l’imposteur qui nous immobilise bien trop souvent.\nPour être tout à fait transparent, je suis régulièrement confronté à ces blocages. En premier lieu en moi-même. Mais aussi chez les personnes que j’ai le plaisir de côtoyer depuis des années dans mon travail. Voici quelques conseils que je tente de suivre et que j’essaye de transmettre. À prendre avec toutes les précautions d’usage, ce qui fonctionne pour moi ne fonctionne pas nécessairement pour tout le monde…​\nRéfléchir beaucoup, écrire vite C’est sûrement la meilleure définition de mon mode de fonctionnement. Il me faut souvent des jours, voire des mois pour rédiger un article. Il faut du temps pour qu’un sujet mature réellement, j’y travaille bien souvent en tâche de fond. Vous savez, comme ces bugs que l’on résout à des moments improbables, sous la douche, etc.\nMais comme on travaille toute la journée, il est bien souvent difficile d’avoir un train de pensée continu, que l’on peut reprendre là où on l’a laissé. Alors, il faut prendre des notes, mettre des articles en favoris pour les retrouver facilement, bref tout ce qui permet de s’alimenter quand on retrouve un moment de libre.\nEnsuite, rien n’empêche d’écrire le plan de son article, en y balançant quelques liens comme autant de références et d’ancres pour son soi du futur.\nC’est un process global qui prend plus ou moins de temps, selon les gens, selon les sujets, mais que je trouve particulièrement adapté à nos quotidiens déjà bien chargés. Et puis …​ vient le moment de se lancer ! Et là, la rédaction peut se faire très vite !\nÀ l’opposé de cette période de réflexion où l’on rassemble ses sources et ses idées, la rédaction coule de source, puisque l’on a déjà tout en tête ! Lorsque l’on aime écrire, c’est même un moment assez jouissif : en quelques minutes on peut rédiger plusieurs dizaines de lignes sans les voir passer, puisque tout est déjà en place. C’est alors une sorte de libération, tout tombe enfin en place et notre cerveau peut se vider en même temps.\nLes premiers jets des articles qui ont été préparés bien en amont sont souvent des versions définitives à peu de choses près. Il m’arrive ainsi assez souvent de n’avoir que quelques jours entre le début de la rédaction et la publication d’un post, le temps de le relire à froid. Et de le faire relire pour éviter de raconter trop de bêtises.\nSe fixer des objectifs On le sait, la procrastination est d’autant plus forte quand on n’a pas envie de faire une tâche. Et pourtant, dans notre cas, il est important de surmonter nos travers habituels. Je vous recommande pour cela de vous fixer des objectifs, tenables si possible. Par exemple, pourquoi ne pas viser un article par mois pour commencer ?\nDans le même temps, lors des périodes de creux, il est très intéressant de se constituer des \u0026#34;réserves\u0026#34; de posts à publier plus tard. On peut alors procrastiner un peu sur les suivants !\nDe manière à maintenir le rythme, on peut alterner entre plusieurs types d’articles, plus ou moins longs à rédiger. Cela permet de reprendre son souffle entre deux tutoriels particulièrement corsés par exemple.\nNe pas hésiter à découper en plusieurs articles Souvent, lorsque l’on s’attaque à un sujet pour rédiger un article, on en découvre de nouveaux aspects ou des éléments que l’on ne maîtrisait pas. C’est cool, ça veut dire que l’on apprend des choses ! Mais en contrepartie on se retrouve avec une montagne de sujets à adresser, ce qui rallonge la durée de notre réflexion, celle de la rédaction, mais surtout débouche sur un article-fleuve qui ne sera pas digeste.\nIl faut alors ne pas hésiter à découper son article en plusieurs. Si possible de manière logique (en s’appuyant sur le plan que l’on évoquait plus haut par exemple). Et puis c’est aussi un excellent moyen d’augmenter le nombre de publications, et par là même son référencement, sa satisfaction personnelle, etc.\nEn revanche, il ne faut pas chercher à tirer à la ligne, ça se ressent pour le lecteur. Il vaut mieux viser la concision et aller droit au but …​ ce que j’ai beaucoup de mal à faire !\nNe pas hésiter à attaquer des sujets que l’on ne maîtrise pas à 100% Nous l’avons vu, le syndrome de l’imposteur a très souvent tendance à nous inhiber. Et pourtant il faut se lancer…​ Même en prenant son courage à deux mains, force est de reconnaitre qu’il est difficile de se sentir suffisamment légitime pour rédiger un article sur un sujet que l’on n’a pas l’impression de maîtriser à 100%.\nMais en fait, si seuls les experts écrivaient des articles, il y aurait bien peu de publications pour nous guider quand on cherche de l’aide sur internet ! Alors, on se lance et on raconte n’importe quoi ? Non ! Il est tout à fait possible de signaler les points que l’on ne comprend pas, y revenir plus tard, etc. Déjà parce que l’on ne connait jamais tout, et ensuite parce que c’est un excellent moyen de se former !\nEn faisant vos recherches, vous allez acquérir des connaissances que vous n’aviez pas encore, tout simplement parce que vous n’en aviez pas eu besoin pendant votre phase de développement par exemple. Mais la rédaction de votre article vous permettra d’améliorer vos compétences, c’est doublement gagnant !\nPlus tard, en continuant de travailler sur le même sujet, vous allez peut-être comprendre de nouvelles choses, découvrir que vous ne respectiez pas les meilleures pratiques …​ et cela vous permettra de rédiger un article en plus, pour montrer l’évolution de votre savoir. Une autre occasion de le faire : lors d’une mise à jour majeure d’un outil que vous présentiez par exemple !\nQue pensez-vous de ces conseils ? Est-ce que vous allez vous lancer ?\nJe vous propose d’aller encore un cran plus loin, pour améliorer la qualité de vos posts de blog, dans un prochain article !\n","permalink":"https://alainnicolas.fr/fr/blog/blog-it-yourself-mon-experience/","tags":["Blogging"],"title":"Blog It Yourself - Mon expérience"},{"categories":null,"contents":" Vous avez un beau blog, peut-être grâce à l’article précédent, et vous peinez à y écrire des articles ? C’est normal…​ Les blocages sont nombreux et réels.\nLes \u0026#34;excuses\u0026#34; pour ne pas se lancer sont nombreuses. Et la plupart du temps on y croit dur comme fer ! Je vous propose les trois raisons principales que j’ai entendues pour ne pas écrire d’article.\nJe n’ai pas le niveau pour écrire des articles Clairement la raison principale qui nous empêche tous de nous lancer. Ce fameux \u0026#34;Syndrome de l’Imposteur\u0026#34;…​\nJ’ai longtemps cru que c’était réservé aux plus juniors d’entre nous, mais force est de constater que …​ pas du tout ! Et comment je le sais ? Déjà parce que je le ressens toujours, et ensuite parce que j’en entends régulièrement parler par des développeurs beaucoup plus expérimentés que moi.\nDonc le souci n’est pas dans l’expérience réelle, mais dans le ressenti de celle-ci ! Et ça, c’est important ! Cela veut tout simplement dire qu’il n’y a pas un moment dans une carrière qui serait meilleur qu’un autre pour écrire un article et que, vous aussi, vous pouvez le faire.\nEt pour aller plus loin, il faut aussi se dire que les points de vue d’un développeur junior et d’un développeur senior sont suffisamment éloignés pour que les deux puissent s’exprimer, sans que l’un invalide l’autre. Si vous en doutiez encore, il y a de la place pour tout le monde sur internet…​\nJe n’ai pas d’idées d’article à rédiger Ah, ça on l’entend souvent aussi ! Et pourtant, c’est probablement la raison la moins valable…​\nTous les développeurs savent faire des choses. Plein de choses même, avec des outils très variés, plus ou moins exotiques. Il n’y a pas deux projets identiques, il y a toujours des contextes différents, des clients avec des caractéristiques bien à eux, etc. Donc, il y a une source inépuisable d’idées pour nous alimenter !\nEn premier lieu, il faut penser aux retours d’expérience. Déjà parce que l’on a tous des \u0026#39;expériences\u0026#39;, que les autres n’ont pas. Ensuite, parce que l’on ne peut pas avoir tort lorsque l’on parle de ce que l’on a vu et vécu. Personne n’est mieux placé que vous pour parler de votre expérience personnelle !\nEt puis on peut imaginer plein de petits sujets qui méritent que l’on y consacre du temps ! Par exemple, pourquoi ne pas rédiger un petit tutoriel sur un outil que vous utilisez régulièrement ? Parce qu’il en existe déjà des tas ? Peut-être, mais personne ne l’utilise comme vous l’utilisez, avec le raccourci qui vous fait gagner du temps, etc.\nEn fait, quand on y réfléchit, on a TOUS des choses à raconter. Il suffit de penser à tout ce que l’on a fait dans la semaine, en retirant les barrières que l’on se met trop facilement !\nJ’ai peur de raconter des bêtises Dans la lignée des deux raisons précédentes, évidemment. En y ajoutant une dose de timidité…​\nAlors, le plus simple est bien entendu de se faire relire. Par quelqu’un de plus senior si cela vous rassure, mais n’importe qui fera l’affaire en réalité ! Un junior pourra justement vous dire si l’article est abordable, s’il manque une définition pour tout comprendre, etc.\nEn contrepartie, il faut être prêt à accepter les conseils, les remarques, les corrections syntaxiques…​ Hé oui, notre ego nous rattrape parfois, même au beau milieu d’un épisode de syndrome de l’imposteur !\nMais malgré tout vous ne vous sentez pas de vous lancer, de peur de perdre la face ? Qu’avez-vous à perdre, en vrai ? Pas grand-chose, à moins d’avoir lourdement menti sur votre CV ! Si je me rends compte que je n’ai raconté que des bêtises dans mon précédent article, c’est parfait, j’ai déjà l’idée du suivant qui va devoir expliquer à quel point je me suis trompé !\nEt pour les erreurs plus basiques, une correction est vite mise en ligne, donc pas de panique. Contrairement à Twitter, vous pouvez vous reprendre et la correction passera probablement inaperçue !\nLes blocages sont nombreux et dépendent de chacun d’entre nous, mais aussi de notre entourage et de sa capacité à nous faire grandir. Dans le prochain article je vous partage mon expérience sur le sujet !\n","permalink":"https://alainnicolas.fr/fr/blog/blog-it-yourself-ce-qui-nous-bloque/","tags":["Blogging"],"title":"Blog It Yourself - Ce qui nous bloque"},{"categories":null,"contents":" J’évoquais le choix et l’utilisation de Ghost comme outil de blogging. Après 18 mois d’exploitation, pour les raisons évoquées à la fin de l’article précédent, j’ai décidé de changer de plateforme. Et puis aussi parce qu’après les 12 mois gratuits de l’instance AWS il fallait bien payer, même si cela reste des petites sommes.\nGénérateur de sites statiques ? Il faut tout d’abord comprendre qu’il ne s’agit pas que d’un changement de solution technique, mais d’un changement d’état d’esprit. WordPress ou Ghost sont des logiciels qui exposent un site ainsi que des outils de rédaction et d’administration. À l’inverse, Hugo n’est qu’un générateur de sites. À partir d’un thème et d’une liste de contenus, il va générer des pages HTML …​ et c’est tout !\nAutrement dit, toute la création, la gestion et la rédaction du site se font sur l’ordinateur de son propriétaire. En contrepartie, les pages générées n’ont pas besoin d’une API ou d’un quelconque serveur pour les alimenter. Donc le site n’est pas \u0026#34;piratable\u0026#34; en tant que tel. Tout dépendra de la manière d’héberger ces pages HTML évidemment.\nLà où WordPress et Ghost assurent la mise en ligne en direct des modifications qui sont faites et perdent donc la version précédente, Hugo simplifie grandement les choses : il est très facile de versionner les fichiers \u0026#34;texte\u0026#34; qui le composent, via Git.\nOn peut donc versionner le contenu du site (les articles du blog, etc.), mais aussi le thème du site en lui-même. Ce qui permet de revenir en arrière après une mise à jour malheureuse par exemple, sans avoir à retrouver les 36 options modifiées sur un WordPress.\nÀ noter qu’il existe des dizaines de générateurs de sites statiques, avec des caractéristiques différentes, écrits dans des langages différents, etc. Je vous invite à consulter la liste sur le site de la JAMStack (et au passage à vous renseigner sur la JAMStack, même si ce n’est pas précisément le sujet ici).\nParmi ses concurrents directs (Jekyll et Gatsby), Hugo ressort d’une courte tête en nombre d’étoiles sur GitHub, si tant est que ce soit un indicateur important au moment de faire son choix…​\nThèmes Admettons que l’on se lance avec Hugo. Une fois l’outil installé sur son poste, encore faut-il trouver le thème qui correspond à son besoin et ses goûts. Heureusement, tout est prévu sur la page officielle des thèmes. Avec une bonne catégorisation des thèmes et des sites de démonstration, il est assez facile de trouver son bonheur.\nC’est ainsi que j’ai trouvé celui créé par Eddie Webbinaro, sobrement intitulé Resume.\nVous ne trouvez pas ce qu’il vous faut ? Pas de panique ! Certes, vous pouvez créer votre propre thème (comme décrit dans ce post par exemple), mais sachez que de nombreux thèmes ne sont pas référencés sur la page officielle, vous pouvez donc faire vos propres recherches.\nPour l’anecdote, j’ai trouvé une version dédiée à Hugo du thème par défaut de Ghost en faisant une recherche rapide. C’est ainsi que RoxTheCasbah n’a même pas changé d’aspect lors de sa migration de Ghost vers Hugo ! Et si ça vous intéresse, ce thème (Casper 3) est disponible ici.\nExtrait de la liste des thèmes pour Hugo\rDe la même manière que l’on peut se lancer dans la création de son propre thème, il est bien évidemment possible de modifier un thème existant. Attention à la licence attachée à celui-ci tout de même !\nPar exemple, je n’avais pas besoin de certaines sections proposées par le thème Resume dont je parlais plus haut, je les ai donc supprimées, j’ai ajouté d’autres pages, etc. Idem pour améliorer (selon mes goûts), l’affichage d’un post de blog, etc.\nAttention toutefois, il faut bien reconnaitre qu’en modifiant le thème on peut rapidement s’éloigner de sa version d’origine et rendre impossible sa mise à jour en local si l’auteur le modifie de son côté.\nDe plus, Hugo est livré avec des comportements par défaut très pratiques, mais aussi très contraignants. Par exemple, par défaut, Hugo prend l’entrée description d’un document Markdown pour générer la balise \u0026lt;meta name=\u0026#34;description\u0026#34;\u0026gt; qui représentera votre page sur les moteurs de recherche. Gare à vous si vous l’avez par exemple nommée extract (ce qui peut être très logique) : la page n’aura tout simplement pas de description et c’est très pénalisant en termes de référencement chez Google !\nContenu Votre thème est en place ? Il n’y a plus qu’à ajouter du contenu à votre site !\nEt c’est pour moi le meilleur moment pour se rendre compte de la puissance proposée par Hugo : tout peut être \u0026#34;markdownifié\u0026#34;. Autrement dit, tout le contenu de votre site peut se rédiger dans des fichiers texte, au format Markdown par défaut. Cela signifie donc que pour modifier le contenu de votre page \u0026#34;Accueil\u0026#34;, nul besoin de chercher dans quel fichier HTML se trouve l’information, il suffit de retrouver le fichier accueil.md probablement rangé à la racine de votre projet.\nJ’en parlais dans un article début octobre 2021, il est possible d’aller plus loin qu’avec Markdown en utilisant le langage AsciiDoc. Et il est possible d’avoir une partie du contenu en Markdown et le reste en AsciiDoc, c’est pratique lorsque l’on part d’un site existant notamment.\nLogo Asciidoctor\rLa documentation de Hugo est très bien faite et l’énorme communauté anime un forum d’entraide très riche. C’est par exemple comme cela que l’on peut trouver les informations nécessaires à la mise en place d’un système de tags pour catégoriser ses articles ou encore le code nécessaire pour garantir l’intégration de vidéos YouTube sur une page.\nLa génération du site est incroyablement rapide, de l’ordre de quelques secondes pour un site qui comporte plusieurs centaines de pages. C’est un argument mis en avant par Hugo et très pratique en cours de rédaction d’un article ou de modification de la structure d’une page : la modification est affichée instantanément.\nHébergement \u0026amp; Déploiement On l’a dit, Hugo ne génère que des pages HTML, il faut ensuite se charger de les héberger. Évidemment, si vous avez un serveur à la maison cela se fera sans soucis, d’autant qu’il n’y a pas besoin d’une machine de guerre pour servir de telles ressources. Pour les autres, il existe des solutions …​ gratuites !\nÉvoquons tout d’abord GitHub Pages (et son pendant chez GitLab …​ GitLab Pages). Ces services sont mis à disposition gratuitement par vos plateformes de gestion de sources préférées.\nIl existe des différences entre les deux, la configuration ne se fait pas exactement de la même manière, mais l’idée à la fin est la même, on dispose d’une page web (ou d’un site complet) hébergée sur un serveur distant et accessible de partout.\nPar la même occasion, on bénéficie des performances et de la fiabilité de ces entreprises majeures. Disons que si notre page n’est plus accessible, il y a de fortes chances que de très nombreux autres sites soient en réalité inaccessibles au même moment.\nÀ titre d’exemple, mon site et RoxTheCasbah sont hébergés par GitHub Pages.\nNous pouvons aussi parler de Netlify qui offre cette fois-ci un service 100% dédié à l’hébergement, avec une version gratuite qui suffit complètement à héberger un site et une version payante pour aller plus loin (travail en équipe, etc.). En s’interfaçant avec votre repository GitHub par exemple, Netlify sera capable de détecter les changements, builder la nouvelle version du site et la déployer immédiatement.\nÀ noter que le déploiement automatique n’est pas toujours une bonne idée, on risque de se retrouver avec un article non terminé déployé aux yeux de tous. Il faut donc envisager un déploiement déclenché manuellement pour votre site en production, tout en conservant une livraison automatique pour une version en recette par exemple.\nC’est ainsi que je me sers de Netlify pour déployer des versions différentes de mon site, par exemple avec des nouvelles fonctionnalités à tester en conditions proches du réel ou des articles encore en brouillon. Mais je peux aussi très facilement faire basculer la version \u0026#34;en production\u0026#34; de GitHub vers Netlify si ce premier service devenait payant ou connaissait une panne majeure, avec un simple changement de redirection DNS.\nUne fois déployé par GitHub Pages, le site est disponible à l’adresse pseudo.github.io, soit alainncls.github.io dans mon cas. Ce n’est pas encore très personnalisé…​ Et c’est sans parler des adresses par défaut de Netlify qui ressemblent à stoic-franklin-0f67b8.netlify.app ou reverent-stonebraker-e22885.netlify.app !\nIl convient donc de \u0026#34;cacher\u0026#34; ces adresses par un nom de domaine plus propre. Il s’agit cette fois-ci d’une opération payante. Au passage, attention aux offres trop belles pour être vraies : n’achetez pas votre nom de domaine n’importe où ! De mon côté, je passe par le service de Google, Google Domains.\nConclusion Pour résumer les aspects positifs de Hugo, nous pouvons évoquer :\nle gain en sécurité,\nle versioning du thème et du contenu,\nsa gratuité,\nsa rapidité à générer des sites comprenant des centaines de pages,\nla facilité d\u0026#39;héberger gratuitement des pages HTML,\net enfin la très riche communauté autour de l’outil.\nIl convient de nuancer cet enthousiasme en évoquant quelques points négatifs :\nla difficulté, voire l’impossibilité, de changer de thème si celui d’origine a été fortement modifié,\nl’obligation de respecter des standards contraignants sous peine de devoir faire énormément de développements à la main,\net le plus grand risque de faire des bêtises en termes de référencement sur le site en entier.\nMaintenant que nous avons vu plusieurs solutions techniques pour créer un blog, nous verrons dans le prochain article comment rédiger des posts, même si on a l’impression de ne rien avoir à raconter…​\n","permalink":"https://alainnicolas.fr/fr/blog/blog-it-yourself-hugo/","tags":["Blogging","Hugo"],"title":"Blog It Yourself - Hugo"},{"categories":null,"contents":" En faisant le ménage dans mes repositories sur GitHub, je suis retombé sur de vieux projets, parfois antiques. Ne nous étendons pas sur la honte que l’on peut ressentir en jetant un œil sur du code écrit il y a presque 10 ans, c’est forcément très moche…​\nMais un élément a capté mon attention : de très nombreux commits ne sont pas associés à mon pseudo ou ne présentent pas ma photo de profil. Étrange, puisque les plus récents semblent correspondre à mon pseudo et affichent ma photo.\nQu’est-ce qui a changé entre temps ?\nLa réponse est venue assez vite : j’ai souvent changé d’adresse mail au cours des années (école, premier emploi, nouvelle adresse personnelle et ainsi de suite). Alors, je sais que l’on peut modifier l’auteur d’un commit, son pseudo ou son adresse mail. Mais sur des centaines de commits parmi des dizaines de repositories, comment dire …​ la vie est trop courte ?\nEn fait, tout est une question d’outillage.\nÀ la main ... c\u0026#39;est long\rAvec les bons outils ... c\u0026#39;est mieux\rLe bon outil, je l’ai trouvé sur StackOverflow (à noter que l’on retrouve cette réponse sur plusieurs dizaines de posts). Tout réside dans la commande filter-branch qui est capable de parcourir tous les commits du projet et de leur appliquer des modifications.\nVous sentez le potentiel ? Oui, il y a de quoi détruire votre historique, donc on y va doucement hein !\nDans mon cas, je devais modifier les commits écrits avec une certaine adresse mail et y faire figurer mon unique adresse actuelle ainsi que mon pseudo pour tout harmoniser. La ligne de commande ressemble donc à cela :\ngit filter-branch -f --env-filter \u0026#39; OLD_EMAIL=\u0026#34;old.email@example.com\u0026#34; CORRECT_NAME=\u0026#34;New Name\u0026#34; CORRECT_EMAIL=\u0026#34;new.email@example.com\u0026#34; if [ \u0026#34;$GIT_COMMITTER_EMAIL\u0026#34; = \u0026#34;$OLD_EMAIL\u0026#34; ] then export GIT_COMMITTER_NAME=\u0026#34;$CORRECT_NAME\u0026#34; export GIT_COMMITTER_EMAIL=\u0026#34;$CORRECT_EMAIL\u0026#34; fi if [ \u0026#34;$GIT_AUTHOR_EMAIL\u0026#34; = \u0026#34;$OLD_EMAIL\u0026#34; ] then export GIT_AUTHOR_NAME=\u0026#34;$CORRECT_NAME\u0026#34; export GIT_AUTHOR_EMAIL=\u0026#34;$CORRECT_EMAIL\u0026#34; fi \u0026#39; --tag-name-filter cat -- --branches --tags Une fois ces modifications faites en local, encore faut-il les envoyer sur le répertoire distant :\ngit push -f --tags origin HEAD:main Et nettoyer les références locales :\ngit update-ref -d refs/original/refs/heads/main On observe alors que l’historique affiche bien les commits comme étant les nôtres :\nExtrait d\u0026#39;un vieux projet en Java 7\rEt ce qui ne fait pas de mal à l’égo : soudainement on a plus de commits comptabilisés par GitHub sur sa page de profil ! 😉\n","permalink":"https://alainnicolas.fr/fr/blog/reecrire-historique-git/","tags":["Git","GitHub"],"title":"Réécrire son historique Git (et vite)"},{"categories":null,"contents":" Je l’évoquais dans mon article relatif au choix d’un blog, le premier choix pour créer le blog RoxTheCasbah s’est porté sur Ghost.\nC’est ainsi que je vous propose un retour d’expérience sur l’installation, le paramétrage et l’utilisation de Ghost, qui se présente comme une alternative à WordPress, plus simple, plus légère et plus moderne.\nL’hébergement Laissons de côté la version payante de Ghost qui propose un hébergement par l’entreprise, et donc un minimum de paramétrage pour l’utilisateur. Concentrons-nous sur la version gratuite et open-source de l’outil, à héberger soi-même.\nParce qu’il n’y a jamais de mauvaise occasion d’apprendre quelque chose, nous avons choisi d’héberger le blog sur une instance AWS gratuite pour ne pas engendrer le moindre coût alors jugé inutile dans l’attente de connaître la fréquentation du site.\nOffre AWS\rAWS propose en effet une version gratuite pendant un an d’une des plus petites machines sur son service EC2. Les spécifications de cette machine répondent globalement aux prérequis recommandés par Ghost dans sa documentation, nous ne sommes pas allés plus loin !\nL’installation Là encore, le but est d’aller au plus simple et rapide, grâce à la documentation assez exhaustive de Ghost décrivant l’installation manuelle sur différents OS et dans différentes configurations. Nous nous sommes dirigés vers le guide \u0026#39;Ubuntu\u0026#39;.\nÀ noter que Ghost fournit un petit utilitaire pour gérer son site, de l’installation à la mise à jour : Ghost CLI.\nAvec cet outil installé (npm i -g ghost-cli), il ne reste plus qu’à lancer la commande ghost install, répondre à quelques questions (nom du site, URL, etc.) et le tour est joué :\n$ ghost install ✔ Checking system Node.js version ✔ Checking logged in user ✔ Checking current folder permissions ✔ Checking memory availability ✔ Checking free space ✔ Checking for latest Ghost version ✔ Setting up install directory ✔ Downloading and installing Ghost v4.2.2 ✔ Finishing install process ? Enter your blog URL: https://myblog.com ? Enter your MySQL hostname: localhost ? Enter your MySQL username: mycoolname ? Enter your MySQL password: [hidden] ? Enter your Ghost database name: ghost_prod Le lancement Une fois le site lancé (ghost start), une rapide navigation nous assure que tout semble fonctionner comme attendu. Il est désormais possible de créer un compte administrateur et un ou plusieurs compte(s) \u0026#34;rédacteur(s)\u0026#34;, depuis l’interface du site. La rédaction d’articles peut démarrer sans soucis !\nSoyons clairs : c’est top ! Sans trop d’effort on se retrouve avec un site opérationnel, un back office exhaustif et un éditeur de texte sympathique.\nJ’insiste sur l’éditeur de texte, il est du niveau de ce que l’on peut trouver sur Medium, et largement supérieur à ce que propose WordPress. Et on peut même rédiger ses articles en Markdown !\nJe parlais justement de Markdown dans une série d’articles au sujet de la \u0026#34;Documentation as Code\u0026#34;.\nLes améliorations Si le site obtenu au premier lancement est pleinement opérationnel, il faut noter que de nombreuses optimisations sont à réaliser presque obligatoirement pour obtenir un blog rapide et bien référencé.\nNGINX, performances et référencement Avoir un blog, c’est bien, avoir un blog référencé par les moteurs de recherche, c’est mieux !\nEn suivant le processus d’installation, Ghost utilise Nginx comme reverse proxy. En modifiant sa configuration par défaut, on peut obtenir des performances plus élevées que celles déjà correctes au premier lancement. Ces optimisations de performances concernent notamment les images et la mise en cache côté navigateur.\nComme il ne serait pas très intéressant de paraphraser des articles déjà bien complets, je vous encourage à jeter un œil ici et là.\nCommentaires et contact Une fois le blog en ligne et les premiers articles rédigés, c’est assez naturellement que de nouveaux besoins se font sentir.\nPar exemple, comment obtenir un module de commentaires sous les articles pour échanger avec sa communauté naissante ? Une solution nous est apparue assez simplement : Disqus, même si d’autres outils existent aussi. L’intégration de cet outil est prévu presque nativement dans la documentation de Ghost, le setup se fait donc très rapidement.\nUne autre fonctionnalité assez courante est la page de contact pour permettre aux visiteurs de contacter l’auteur du blog de manière plus \u0026#34;privée\u0026#34;. Là aussi, plusieurs services tiers peuvent faire l’affaire. Nous avons choisi Formspree, qui permet de gérer plusieurs types de formulaires. Une nouvelle fois, une page lui est dédiée dans la documentation.\nÀ noter que de nombreuses intégrations sont documentées par Ghost, la plupart des besoins semblent couverts !\nLes nombreuses fonctionnalités Ghost propose la liste de fonctionnalités de son outil sur une page dédiée. Et le moins que l’on puisse dire c’est qu’elles sont très nombreuses.\nDans un premier temps, c’est extrêmement excitant : le blog que je suis en train de mettre en place va savoir faire énormément de choses à ma place, c’est génial. Et puis dans un second temps, on peut commencer à se dire qu’il n’est pas si léger et simple que ce qui était promis au début…​\nC\u0026#39;est une usine à gaz, vous me suivez ?\rParmi les fonctionnalités qui mettent WordPress au placard, je citerai la gestion d’un workflow de publication, avec une notion de relecture et d’auteurs multiples. C’est très intéressant, notamment pour un blog semi-professionnel où les publications doivent être les plus réussies possibles dès leur mise en ligne.\nEt dans les fonctionnalités qui viennent presque en trop, citons la gestion des membres gratuits et payants : cela ne s’adresse qu’à une frange des auteurs en ligne, tout le monde n’a pas besoin d’un système digne d’un quotidien national.\nFranchement, vous payeriez pour me lire ? (Si la réponse est \u0026#34;oui\u0026#34;, envoyez-moi un chèque, pas de souci !) Allez, à la limite la mise en place d’une newsletter pour être prévenu des nouvelles publications, pourquoi pas.\nLa conclusion Ghost est une bonne solution pour monter son blog rapidement, et vite se concentrer sur la rédaction d’articles. J’ai été convaincu, puisqu’en quelques clics et lignes de commande, j’ai obtenu un blog très complet.\nNéanmoins, dans sa version autohébergée, Ghost n’est pas sans soulever des difficultés :\nIl faut assurer la sécurité de son instance AWS, de Nginx et Ghost en lui-même\nLe paramétrage par défaut n’est pas suffisamment optimisé\nLes mises à jour sont nombreuses (55 en 2021, dont une version majeure, heureusement très bien documentée)\nIl est un peu lourd pour l’instance gratuite AWS EC2\nNotons aussi ses (trop) nombreuses fonctionnalités qui vont au-delà de son slogan d’origine : \u0026#34;Just a blogging platform\u0026#34;.\nDans le prochain article, je vous raconte comment je suis passé de Ghost à Hugo, avec un changement de philosophie radical.\n","permalink":"https://alainnicolas.fr/fr/blog/blog-it-yourself-ghost/","tags":["Blogging"],"title":"Blog It Yourself - Ghost"},{"categories":null,"contents":" Selon moi, tous les développeurs devraient tenir un blog ! OK, mais comment faire ? Explorons les outils et les techniques de rédaction.\n","permalink":"https://alainnicolas.fr/fr/series/blog-it-yourself/","tags":null,"title":"Blog It Yourself"},{"categories":null,"contents":" Lorsque l’idée de créer un blog pour partager ses passions est venue à ma compagne, la question du choix technique s’est très vite posée. Entre développeurs (\u0026#34;geeks\u0026#34; diront certains), on ne pouvait pas échapper au débat…​\nAlors oui, depuis des années et pour encore un bon moment, celui qui veut créer son site rapidement a de fortes chances de se tourner vers WordPress. Tout simplement parce que la plateforme a fait ses preuves depuis longtemps et est de loin la plus utilisée. Plus de 40% des sites actuellement en ligne sont basés sur WordPress (source : Kinsta). C’est tout simplement énorme…​\nLa jungle Pour autant, est-ce que tout le monde a réellement besoin d’une machine de guerre aussi complexe que WordPress ? Et est-ce que tout le monde veut avoir la même interface ou les mêmes failles de sécurité ? Pas si sûr…​\nNous voulions éviter l’usine à gaz au rendu standardisé, et c’est ainsi que notre voyage dans le monde merveilleux des CMS a débuté. (CMS = Content Management System, autrement dit un système qui permet de générer et gérer un site web.)\nIl y a ceux qui sont orientés e-commerce comme Magento, ceux qui sont dépassés comme Typo3 ou Drupal, ceux qui sont (trop) complets comme Joomla…​\nLes CMS pensés pour les blogs En creusant un peu plus, en filtrant davantage sur ceux qui sont réellement dédiés à la création de blogs, on trouve d’autres solutions, peut-être moins connues.\nSite de démonstration Squarespace\rIl y a le géant Medium qui permet de rédiger des articles et enfin de personnaliser leur apparence depuis quelques mois, mais pas de l’héberger là où vous le souhaitez. Ou encore Squarespace qui propose des sites très visuels, mais en réalité plutôt destinés à des créateurs de contenu graphique.\nLe coût Et puis avant de lancer un site, difficile de savoir si celui-ci va avoir du succès et donc mériter que l’on dépense de l’argent pour le créer, l’héberger et le maintenir. L’un de nos critères non négligeables était donc de trouver une solution gratuite, a minima pour commencer notre voyage.\nLe blog officiel de Serendipity\rMention spéciale pour le look délicieusement rétro de Serendipity, le blog qui se veut volontairement \u0026#34;pas mainstream depuis 2002\u0026#34;. Mais, tant qu’à faire, autant rester ancrés dans le XXIe siècle…​\nAlors, une solution gratuite, oui, mais pas au détriment du rendu final.\nLa simplicité Pour faire bonne mesure, nous ne comptions pas nous en tenir à ces critères, il en restait un de taille : la simplicité. Rédiger des articles sur ses passions doit rester un plaisir et une expérience facile. C’est ainsi qu’il fallait une solution proposant un éditeur de texte le plus simple possible.\nEt quoi de mieux pour être à l’aise que d’utiliser ses outils favoris du quotidien ? En tant que développeurs, nous avons l’habitude de rédiger de la documentation en Markdown ou Asciidoc, alors pourquoi changer nos habitudes ?\nDes solutions existent pour générer des pages web classiques à partir de ces langages, comme Jekyll qui serait le plus populaire ou Hugo qui serait le plus rapide. Le fonctionnement est simple : on définit un template de présentation, on rédige son article dans un fichier texte et le logiciel génère des pages web n’ont plus qu’à être déposées sur un serveur.\nOn y gagne en rapidité (à peine quelques secondes pour générer un site de plusieurs dizaines d’articles avec Hugo) et en sécurité (impossible de \u0026#34;hacker\u0026#34; des fichiers HTML basiques).\nEn revanche, même si les communautés sont très vivantes, il n’existe encore que peu de templates réellement modernes et attrayants. Encore une fois, il serait dommage de sacrifier le rendu final du site au nom de la simplicité.\nHébergement Écrire des articles, que l’on parle de tricot ou de blockchain, c’est partager une partie de soi et de ses idées. Alors autant avoir la main sur ces articles…​\nC’est ainsi qu’après le critère de gratuité et celui de simplicité, celui de la maîtrise de l’hébergement s’imposait à nous. Si de nombreuses plateformes proposent d’héberger votre WordPress en fournissant un nom de domaine, des adresses mail et autres services plus ou moins utiles, elles ne vous laisseront pas réellement la main sur vos propres données, vos propres idées, votre propre production…​ Et puis, qu’est-ce qui vous protège d’une augmentation de tarif ? De nouvelles conditions quant à l’accès à vos anciens articles ?\nMaîtriser l’hébergement de son blog, c’est aussi prendre en charge la responsabilité de la sécurité (configuration, clés d’accès, etc.), ce qui n’est pas totalement anodin et nécessite parfois des connaissances techniques.\nLes grands hébergeurs comme AWS ou OVH proposent des offres gratuites qui peuvent souvent suffire à accueillir un blog.\nEt pour les plus motivés et équipés, il est bien sûr possible d’héberger son blog chez soi, pour atteindre l’idéal de la maîtrise de ses données !\nNotre choix Finalement, il a bien fallu faire un choix…​\nNous nous sommes tournés vers Ghost, un CMS (comme WordPress) à l’éditeur de texte simple et efficace qui offre la possibilité de rédiger ses articles en Markdown ou plus classiquement avec des boutons gras, italique, etc.\nPour commencer, nous avons choisi son thème par défaut qui nous semblait répondre largement à nos besoins, mais notons que de nombreux autres thèmes existent.\nGhost existe en 2 versions :\nPayante (cf. tarifs) pour ne pas se soucier de son hébergement, de sa mise à jour et bénéficier d’un support\nGratuite pour laisser la main à l’utilisateur qui souhaite héberger lui-même son site, mais qui doit donc s’occuper de faire les mises à jour, s’assurer de la sécurité, etc.\nNous avons choisi la deuxième option, d’un niveau de difficulté intermédiaire.\nSur les 3 grands critères évoqués dans cet article, Ghost semble bien cocher les cases :\nGratuité : il propose une solution gratuite pour un public légèrement technique\nSimplicité : sa devise d’origine était \u0026#34;Just a blogging platform\u0026#34; (par opposition à WordPress qui sait tout faire …​ à peu près)\nMaîtrise de l’hébergement : il se plie très bien à notre envie de garder la main sur nos articles\nIl ne restait donc qu’à se lancer et mettre en ligne une première version du blog !\nDans le prochain article, je vous raconte notre mise en place du blog, de son hébergement sur AWS à son optimisation.\n","permalink":"https://alainnicolas.fr/fr/blog/blog-it-yourself-choix/","tags":["Blogging"],"title":"Blog It Yourself - Le choix"},{"categories":null,"contents":" Commençons par une petite citation :\n\u0026#34;New year, new me\u0026#34; — Trop de monde,trop souvent La bonne résolution Évitons les bonnes résolutions que l’on ne tiendra pas. Néanmoins, essayons de nous améliorer régulièrement…​\nPour commencer l’année 2022, j’ai décidé de me passer de Google Analytics pour suivre les visites de mon site. Tout d’abord parce que se passer de Google est toujours une bonne idée, ensuite parce qu’il est possible de faire presque aussi bien sans traquer ses visiteurs.\nJe l’évoquais dans un article en octobre dernier, pour respecter le RGPD et recueillir le consentement de ses visiteurs à être pistés, nous devons nous-mêmes consentir à mettre en place un système (type popover ou bannière), contraignant en plus de dégrader l’expérience utilisateur.\nSouriez, vous êtes traqués\rLa recherche d’une alternative Mes critères étaient :\nUne solution gratuite (je n’ai pas assez de visites pour justifier d’un autre investissement que mon temps)\nUne solution sans cookie (inutile de quitter Google pour offrir trop de données à un autre)\nUne solution en SaaS (en accord avec mon site hébergé via GitHub Pages)\nIl existe des dizaines et des dizaines d’articles qui listent des alternatives à Google Analytics. Plus ou moins bons, plus ou moins à jour, plus ou moins intéressés par vos clics sur des liens affiliés…​\nJ’y ai passé du temps, pour finalement me rendre compte que le meilleur récapitulatif se trouve sous forme d’un repository GitHub : Awesome Analytics qui recense plus d’une centaine d’outils d’analytics, regroupés par catégories.\nMa solution : Insights.io Et mon choix s’est porté sur un outil qui n’est même pas dans cette liste ! Note à moi-même : penser à ouvrir une PR pour proposer l’ajout de la solution retenue dans la liste !\nLe credo d\u0026#39;Insights.io\rJ’ai finalement choisi Insights.io, qui propose :\nUne utilisation gratuite jusqu’à 3000 pages vues par mois (j’en suis bien loin)\nDe ne pas déposer de cookie dans le navigateur du visiteur\nUne interface digne de ce nom sur leur site\nAlors évidemment, le jour où mon site sera très célèbre (ah ah !), il faudra passer à la caisse ou changer d’outil. Et puis mes statistiques ne sont pas chez moi, mais sur les serveurs d’Insights.io, ils ne proposent pas d’auto-hébergement.\nCe n’est donc sûrement pas la solution parfaite. En attendant, l’outil est très simple et fonctionne bien.\nLa mise en place Pour démarrer, rien de plus simple ! Une fois le compte créé, on ajoute un \u0026#34;projet\u0026#34; sur son dashboard. On obtient alors un code (exactement le fonctionnement de Google Analytics en somme), qui sert d’identifiant.\nIl faut alors ajouter à toutes vos pages la librairie JavaScript qui va émettre les informations depuis votre site vers les serveurs d’Insights.io. Pour cela, deux solutions sont décrites sur le repository GitHub de la librairie :\nInstallation via npm install/yarn\nnpm install insights-js Directement depuis le CDN unpkg :\n\u0026lt;script src=\u0026#34;https://unpkg.com/insights-js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; Les statistiques obtenues Comme je vous le disais, les statistiques obtenues sont bien moins complètes que celles fournies par Google Analytics. Ici, pas de géolocalisation de vos visiteurs ou de tunnels conversions incompréhensible sans un PhD en marketing, on va droit à l’essentiel !\nEn premier lieu, le graph du nombre de pages visitées sur 24 heures, par semaine, mois, etc. :\nAperçu du dashboard d\u0026#39;Insights.io - Le graph\rEt parce que les choses sont bien faites, on retrouve tout de même des détails sur les visites qui ont eu lieu, avec les pages les plus vues, le temps passé sur le site, ou encore les OS, navigateurs et écrans des visiteurs. Largement suffisant pour un site comme le mien !\nAperçu du dashboard d\u0026#39;Insights.io - Le détail\rBonus : filtrage des robots Lorsque j’ai mis en place Insights.io sur mon site, j’ai été surpris de voir l’insistance des visites d’un certain \u0026#34;PetalBot\u0026#34; :\nDes statistiques phagocytées par un robot\rRenseignement pris, il s’agit d’un robot d’indexation pour le moteur de recherche proposé par Huawei. Et le moins que l’on puisse dire, c’est qu’il indexe ! Souvent.\nDans l’absolu, je n’ai rien contre cette indexation, qui pourra peut-être me rapporter quelques visites un jour. Mais cela vient largement fausser mes statistiques…​\nJe me suis donc permis de forker la librairie insights-js pour lui ajouter un filtrage des robots, sur la base des \u0026#34;user agents\u0026#34; qu’ils affichent. Encore faut-il connaître les mauvais user agents…​ Et pour cela, encore une fois, un repository GitHub, et plus particulièrement ce fichier !\nMa version de la librairie avec ce filtrage est disponible ici. Par contre, cette fois-ci il faut builder la librairie soi-même, je ne vais pas tout faire hein ! 😘\nRésultat, j’ai pu retirer l’import du script Google Analytics, mais aussi de la librairie Tarteaucitron que j’évoquais il y a quelques mois, ce qui ne peut qu’accélérer le chargement de mon site. Ce qui favorise …​ le référencement par Google !\nHé oui, parce que sans Google pour me référencer, qui visiterait mon site ? 😅\n","permalink":"https://alainnicolas.fr/fr/blog/adieu-google/","tags":["Insights","Tarteaucitron","Blogging"],"title":"Adieu Google (Analytics) !"},{"categories":null,"contents":" Après la présentation générale de Spring REST Docs, je vous propose d’aller un peu plus loin en nous penchant sur des petites améliorations qui feront toute la différence !\nNous continuerons de nous baser sur mon projet de démonstration disponible sur GitHub.\nExposer \u0026#34;automagiquement\u0026#34; la documentation Nous l’avons vu : nous sommes désormais capables de générer une page HTML contenant la documentation de notre API. Mais ce n’est pas le meilleur moyen de la rendre disponible aux consommateurs de l’API, nous pouvons faire mieux que ça !\nEt quel meilleur emplacement que l’application Spring Boot en elle-même ? Pour cela, il faut un peu de paramétrage, grâce au plugin Maven maven-resources-plugin.\n\u0026lt;plugin\u0026gt; \u0026lt;artifactId\u0026gt;maven-resources-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;copy-resources\u0026lt;/id\u0026gt; \u0026lt;phase\u0026gt;prepare-package\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;copy-resources\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;outputDirectory\u0026gt;${project.build.outputDirectory}/static/docs/\u0026lt;/outputDirectory\u0026gt; \u0026lt;resources\u0026gt; \u0026lt;resource\u0026gt; \u0026lt;directory\u0026gt;${project.build.directory}/generated-docs\u0026lt;/directory\u0026gt; \u0026lt;/resource\u0026gt; \u0026lt;/resources\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; Ce code permet de copier le contenu du répertoire target/generated-docs dans un répertoire target/static-docs/docs. Autrement dit la page HTML générée dans un dossier un peu particulier, puisque static est automatiquement servi par Spring. Si vous voulez en savoir plus sur cette caractéristique, Baeldung a évidemment une page dédiée !\nAvec cette configuration, si vous lancez la construction de l’application (mvn package), vous obtenez un fichier JAR qu’il suffit de lancer (java -jar demo-spring-rest-docs-0.0.1-SNAPSHOT.jar). L’API est alors exposée, mais aussi la documentation, accessible sur http://localhost:8080/docs/index.html. Donc dès que l’application sera déployée quelque part, sa documentation sera présente !\nCacher par défaut les trop grands éléments Parfois nous devons documenter des endpoints qui renvoient des réponses relativement longues. Ce qui n’est pas sans alourdir la page de documentation. Heureusement, AsciiDoc a une balise pour résoudre le problème : [%collapsible].\nTout ce qui est contenu dans un bloc ainsi annoté est caché par défaut et le lecteur doit cliquer dessus pour le déplier :\nÉlément trop grand (cliquez ici pour le déplier) [%collapsible] ==== Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget mollis neque. Etiam tempor lacinia lorem eget auctor. Quisque accumsan leo a tincidunt hendrerit. Nam eros ante, scelerisque eu tempus et, vestibulum luctus turpis. Donec id nisi risus. Nullam eu purus vulputate velit pharetra hendrerit. Donec varius, velit vitae aliquam interdum, dui sapien faucibus ipsum, et sollicitudin ligula magna quis velit. Donec luctus sed nisi ac blandit. Phasellus sodales mattis pharetra. Duis dignissim tellus nibh, quis imperdiet turpis pharetra et. Phasellus purus odio, pulvinar vel urna vel, consequat vulputate metus. Nunc elementum ornare eleifend. Pellentesque non dapibus ipsum. Nunc malesuada varius elit, auctor tristique nisl pellentesque sed. Vestibulum justo mauris, molestie ut tincidunt a, condimentum ac turpis. Aliquam eu interdum orci. ==== C’est ainsi que dans la documentation de notre application de démonstration nous retrouvons par exemple :\n.Response [%collapsible] ==== include::{snippets}/getAllCompanies/http-response.adoc[] ==== Alléger la description des requêtes/réponses Pour décrire la requête liée à un endpoint, rien de mieux que le snippet http-request. Celui-ci contient l’URL, le verbe HTTP, les headers et éventuellement le body.\nMais bien souvent, les headers sont nombreux. Notamment ceux liés à la sécurité. Et il en va de même pour la réponse, avec de nombreux headers ajoutés par le framework et son outillage.\nSi ces headers ont un sens métier, tant mieux. Mais s’ils ne font que créer du \u0026#34;bruit\u0026#34;, alors autant les enlever de la description (de la requête comme de la réponse), elle n’en sera que plus claire.\nJe vous propose ainsi un petit utilitaire (ControllerTestUtils) pour éviter de répéter dans chaque test la même suppression de headers :\npublic class ControllerTestUtils { static OperationRequestPreprocessor preprocessRequest() { return Preprocessors.preprocessRequest(removeHeaders(\u0026#34;Content-Length\u0026#34;, \u0026#34;X-CSRF-TOKEN\u0026#34;), prettyPrint()); } static OperationResponsePreprocessor preprocessResponse() { return Preprocessors.preprocessResponse(removeHeaders(\u0026#34;Content-Length\u0026#34;, \u0026#34;Pragma\u0026#34;, \u0026#34;X-XSS-Protection\u0026#34;, \u0026#34;Expires\u0026#34;, \u0026#34;X-Frame-Options\u0026#34;, \u0026#34;X-Content-Type-Options\u0026#34;, \u0026#34;Cache-Control\u0026#34;), prettyPrint()); } } Libre à vous de supprimer tel ou tel header selon vos goûts ou vos besoins.\nSi l’on prend l’exemple du header Content-Type dans la requête de suppression d’une Company, il suffit de l’ajouter à la liste des headers à supprimer (cf. code ci-dessus).\nAvant : DELETE /companies/ID_1 HTTP/1.1 Content-Type: application/json;charset=UTF-8 Host: localhost:8080 { \u0026#34;id\u0026#34; : \u0026#34;ID_1\u0026#34;, \u0026#34;name\u0026#34; : \u0026#34;CoolCorp\u0026#34;, \u0026#34;location\u0026#34; : \u0026#34;Paris\u0026#34;, \u0026#34;creationDate\u0026#34; : \u0026#34;2021-11-06T11:03:53.066+00:00\u0026#34; } Après : DELETE /companies/ID_1 HTTP/1.1 Host: localhost:8080 { \u0026#34;id\u0026#34; : \u0026#34;ID_1\u0026#34;, \u0026#34;name\u0026#34; : \u0026#34;CoolCorp\u0026#34;, \u0026#34;location\u0026#34; : \u0026#34;Paris\u0026#34;, \u0026#34;creationDate\u0026#34; : \u0026#34;2021-11-06T11:01:34.532+00:00\u0026#34; } Générer un fichier OpenAPI \u0026#34;Hé, c’est bien joli tout ça, mais dans mon équipe on a l’habitude d’utiliser Swagger, c’est bien plus complet comme outil, on peut même lancer des requêtes depuis la page de documentation !\u0026#34; — Un développeur qui a ses petites habitudes La remarque est intéressante ! En quittant Swagger, on passe d’une page interactive à une page HTML complètement statique. On perdrait donc au change ? Peut-être …​ mais ne parlons pas trop vite !\nAllons droit au but : il est tout à fait possible de générer un fichier décrivant l’API dans un format \u0026#34;Swagger-compatible\u0026#34;, autrement dit au format OpenAPI. Mais pas par défaut, nous devons ajouter une petite dépendance qui vient étendre les capacités de Spring REST Docs :\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.epages\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;restdocs-api-spec-mockmvc\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.14.1\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; Et lorsque l’on documente un endpoint, il faut désormais importer la méthode document() de cette dépendance :\nimport static com.epages.restdocs.apispec.MockMvcRestDocumentationWrapper.document; En relançant les tests, on s’aperçoit alors qu’un nouveau \u0026#34;snippet\u0026#34; est généré : resource.json.\nNouvel aperçu des fichiers générés\rIl s’agit d’un snippet au format OpenAPI. Il ne reste donc plus qu’à rassembler ces snippets en un seul fichier, un peu comme nous savons déjà le faire pour la version AsciiDoc. Mais cette fois-ci, nul besoin d’un \u0026#34;fichier racine\u0026#34;, nous allons nous servir d’un plugin.\nMais …​ problème en vue ! La dépendance ajoutée ne propose qu’un plugin Gradle et notre projet utilise Maven ! Pas de panique, la communauté est vaste et prévoyante, il existe un plugin pour générer la documentation finale : restdocs-spec-maven-plugin.\nEn l’ajoutant dans la section \u0026#34;build\u0026#34; du fichier pom.xml, nous allons pouvoir générer un fichier au format OpenAPI en plus du fichier HTML précédent :\n\u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;io.github.berkleytechnologyservices\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;restdocs-spec-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.21\u0026lt;/version\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;generate\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;name\u0026gt;Demo Spring REST Docs\u0026lt;/name\u0026gt; \u0026lt;version\u0026gt;${project.version}\u0026lt;/version\u0026gt; \u0026lt;host\u0026gt;localhost:8080\u0026lt;/host\u0026gt; \u0026lt;outputDirectory\u0026gt;${project.build.directory}/generated-docs\u0026lt;/outputDirectory\u0026gt; \u0026lt;filename\u0026gt;openapi\u0026lt;/filename\u0026gt; \u0026lt;specification\u0026gt;OPENAPI_V3\u0026lt;/specification\u0026gt; \u0026lt;description\u0026gt;API description for Demo Spring REST Docs service\u0026lt;/description\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; De la même manière que pour le fichier HTML, comme ce fichier openapi.yml est déposé dans un répertoire exposé, il sera accessible une fois l’application lancée. Et à partir de ce moment-là, libre à vous de le fournir comme point d’entrée à une instance de Swagger UI.\nPour cela, on peut tester rapidement la qualité du fichier généré en démarrant une instance de Swagger UI :\ndocker run -p 80:8080 swaggerapi/swagger-ui Une fois le container démarré, il suffit de se rendre sur http://localhost (Swagger UI fonctionnant sur le port 80 d’après notre commande ci-dessus), et de fournir l’adresse du fichier openapi.yml dans la barre de recherche en haut de la page. La documentation apparait …​ avec tout le fonctionnement habituel de Swagger. Alors, il est satisfait le développeur qui a ses petites habitudes ?\nAperçu de la documentation rendue par Swagger UI\rAlors, est-ce que vous commencez à être convaincu par Spring REST Docs ?\nC’est en tout cas le cas pour ma part et je vais continuer de le déployer sur les projets sur lesquels j’ai le plaisir de travailler !\nLiens utiles :\nComparaison de Spring REST Docs et OpenAPI par Baeldung\nMon projet de démonstration\n","permalink":"https://alainnicolas.fr/fr/blog/make-documentation-great-again-bonus/","tags":["AsciiDoc","Spring REST Docs","Java","Spring Boot"],"title":"Make documentation great again (Bonus)"},{"categories":null,"contents":" Nous avons vu précédemment une présentation du langage AsciiDoc et des avantages de la \u0026#34;Documentation as Code\u0026#34;.\nIl est néanmoins possible de faciliter encore plus la rédaction de la documentation ! En effet, il est de coutume de documenter l’API que l’on développe, pour faciliter sa maintenance et les interactions avec ses \u0026#34;consommateurs\u0026#34;.\nMême si l’une des 4 valeurs de l’agilité promeut \u0026#34;un logiciel fonctionnel plutôt qu’une documentation exhaustive\u0026#34;, nous allons voir que l’on peut proposer les deux en même temps grâce à un outil particulièrement pratique.\nSpring REST Docs Spring REST Docs permet d’alléger grandement la rédaction d’une documentation d’API, en combinant une rédaction manuelle et l’injection de sections autogénérées.\nIl s’appuie sur Spring MVC Test, largement utilisé pour les tests de la couche \u0026#34;web\u0026#34; d’une application Spring. Autrement dit, son ajout sur un projet déjà entamé ne demandera pas une refonte complète de ses tests …​ et c’est évidemment une bonne chose !\nUn projet de démonstration De manière à nous baser sur un exemple concret, je vous propose un petit projet de démonstration disponible sur GitHub.\nDans ces cas-là, inutile d’imaginer un cas d’usage très compliqué, j’ai donc mis en place un simple CRUD manipulant un objet Company. Une Company est définie par un ID, un nom, un lieu et une date de création.\nPour ressembler à un vrai projet, j’ai tout de même ajouté une interaction avec une base MongoDB qu’il faut démarrer avant de lancer l’application. Pour ajouter une Company, on peut donc faire une requête POST avec comme body :\n{ \u0026#34;name\u0026#34;: \u0026#34;CoolCorp\u0026#34;, \u0026#34;location\u0026#34;: \u0026#34;Paris\u0026#34;, \u0026#34;creationDate\u0026#34;: \u0026#34;2021-10-29\u0026#34; } Ajouter la dépendance nécessaire Avant tout, il convient d’ajouter la dépendance \u0026#34;Spring REST Docs\u0026#34; au projet :\nExtrait du fichier pom.xml : \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.restdocs\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-restdocs-mockmvc\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; Quant au reste des dépendances constituant cette application, inutile de les lister ici, elles sont très classiques et indépendantes de l’outil générant la documentation.\nModifier ses tests de Controller pour générer de la documentation Il est alors possible de regarder les tests et d’y ajouter des instructions dédiées à générer les éléments qui nous intéressent. Concentrons sur le test de la requête permettant de récupérer une Company à partir de son ID.\nÀ noter que je me suis contenté de mocker la couche de service pour ces tests de controller, il ne s’agit donc clairement pas de tests end-to-end.\nExtrait de CompanyControllerTest : @Test void getCompany() throws Exception { final String ID = \u0026#34;ID_1\u0026#34;; when(companyService.getCompany(ID)).thenReturn(company1); this.mockMvc.perform(RestDocumentationRequestBuilders.get(\u0026#34;/companies/{id}\u0026#34;, ID)) // (1) .andExpect(handler().handlerType(CompanyController.class)) // (2) .andExpect(handler().methodName(\u0026#34;getCompany\u0026#34;)) .andDo(print()) .andExpect(status().isOk()) .andExpect(content().json(objectMapper.writeValueAsString(company1))) .andDo(document( // (3) \u0026#34;getCompany\u0026#34;, ControllerTestUtils.preprocessRequest(), ControllerTestUtils.preprocessResponse(), pathParameters(parameterWithName(\u0026#34;id\u0026#34;).description(\u0026#34;The requested company id\u0026#34;)), // (4) responseFields( // (5) fieldWithPath(\u0026#34;id\u0026#34;).description(\u0026#34;The company unique ID\u0026#34;), fieldWithPath(\u0026#34;name\u0026#34;).description(\u0026#34;The company name\u0026#34;), fieldWithPath(\u0026#34;location\u0026#34;).description(\u0026#34;The company location\u0026#34;), fieldWithPath(\u0026#34;creationDate\u0026#34;).description(\u0026#34;The company creation date\u0026#34;)))); } Première nouveauté : on utilise un RestDocumentationRequestBuilders pour émettre la requête plutôt qu’un traditionnel MockMvcRequestBuilders. La différence ? Il est chargé de capturer les informations de la requête pour la documenter.\nOn déroule les tests habituels : vérifier que la requête est traitée par la méthode getCompany() du CompanyController, que la réponse porte le code HTTP 200 et contient l’objet prévu.\nNouvelle instruction ! Ici on lance la génération de documentation, sous le nom de \u0026#34;getCompany\u0026#34; pour cette requête. Oublions les 2 lignes suivantes pour le moment.\nDocumentons la partie variable de l’URL : l’ID de la Company est passé en \u0026#34;path parameter\u0026#34;, nous pouvons le décrire (même si dans notre cas ce paramètre est assez facilement compréhensible).\nDocumentons la réponse de la requête : nous pouvons décrire chaque champ constituant la Company.\nDésormais, si vous ajoutez un champ dans l’objet Company sans le documenter dans ce test, il ne passera plus. Idem si vous supprimez un champ, le test ne passera plus, car il cherchera à documenter un élément qui n’existe pas. Il s’agit donc d’une nouvelle sécurité : votre API ne pourra plus évoluer sans que vous en ayez totalement conscience !\nNous avons donc un test qui documente le cas passant le plus évident : lorsqu’une Company correspond à l’ID demandé est trouvée. Lançons-nous dans un nouveau test pour le cas contraire.\nExtrait de CompanyControllerTest avec le test d’une erreur @Test void getCompanyNotFound() throws Exception { final String ID = \u0026#34;ID_3\u0026#34;; when(companyService.getCompany(ID)).thenThrow(new CompanyNotFoundException()); this.mockMvc.perform(RestDocumentationRequestBuilders.get(\u0026#34;/companies/{id}\u0026#34;, ID)) .andExpect(handler().handlerType(CompanyController.class)) .andExpect(handler().methodName(\u0026#34;getCompany\u0026#34;)) .andDo(print()) .andExpect(status().isNotFound()) .andDo(document( \u0026#34;getCompanyNotFound\u0026#34;, // (1) ControllerTestUtils.preprocessRequest(), ControllerTestUtils.preprocessResponse())); } Comme dans le test précédent, on ajoute l’instruction document(…​), cette fois-ci avec un nouvel identifiant (\u0026#34;getCompanyNotFound\u0026#34;) pour différencier la documentation générée dans ce nouveau cas.\nEn revanche, il n’est pas ici utile de générer plus de documentation, dans la mesure où la description du \u0026#34;path parameter\u0026#34; a déjà été faite dans le test précédent, et où la requête ne renvoie rien d’autre qu’une erreur HTTP 404.\nEn lançant les 2 tests que nous venons de voir, des fichiers (on parle de \u0026#34;snippets\u0026#34;) vont être générés sous target/generated-snippets. Et comme par hasard, il s’agit de fichiers .adoc !\nAperçu des fichiers générés\rSi l’on ouvre par exemple getCompany/response-fields.adoc, on pourra y trouver :\n|=== |Path|Type|Description |`+id+` |`+String+` |The company unique ID |`+name+` |`+String+` |The company name |`+location+` |`+String+` |The company location |`+creationDate+` |`+String+` |The company creation date |=== Disons-le : même si l’on voit bien que l’on retrouve des éléments saisis dans le test, ce n’est guère lisible…​ Et puis il n’y a pas moins de 14 fichiers générés pour deux petits tests, qui lirait ça ?!\nIl va donc être temps de générer une documentation plus lisible !\nLe fichier source de la documentation Un fichier pour les gouverner tous. C’est en tout cas l’objectif que nous devons nous fixer pour rendre viable notre documentation.\nNous allons donc ajouter un fichier sous source/asciidoctor : index.adoc. Et c’est là que nous injecterons nos \u0026#34;snippets\u0026#34; (et uniquement ceux qui nous intéressent), avec un peu de texte ajouté manuellement pour rendre l’ensemble plus digeste.\nExtrait du fichier index.adoc qui deviendra la documentation === Get one company // (1) .Request \\include::{snippets}/getCompany/http-request.adoc[] // (2) .Path parameters \\include::{snippets}/getCompany/path-parameters.adoc[] // (3) .Response \\include::{snippets}/getCompany/http-response.adoc[] // (4) .Response fields \\include::{snippets}/getCompany/response-fields.adoc[] // (5) .Response if the company was not found \\include::{snippets}/getCompanyNotFound/http-response.adoc[] // (6) Donnons un petit titre à cette partie de la documentation pour décrire le endpoint documenté en dessous.\nOn injecte un snippet contenant la requête, c’est probablement la meilleure représentation de celle-ci.\nOn injecte un snippet contenant la description du \u0026#34;path parameter\u0026#34;.\nEt le snippet qui illustre la réponse reçue.\nN’oublions pas le snippet qui décrit les champs de la réponse.\nNous avions deux tests sur cet endpoint, pensons à montrer à quoi ressemble la réponse dans le cas où la Company n’est pas trouvée.\nPour le moment nous avons juste créé un squelette de documentation. Selon votre IDE, peut-être que vous apercevez déjà un rendu !\nDe manière à améliorer la documentation, vous pouvez évidemment ajouter une table des matières, un titre principal, etc. Il s’agit là de fonctionnalités et annotations de base d’AsciiDoc, je vous propose de ne pas nous y attarder. Vous pouvez avoir une idée de ce que l’on peut faire en regardant le fichier index.adoc du projet de démonstration.\nGénérer la documentation Maintenant que nous savons générer des \u0026#34;snippets\u0026#34; et que nous pouvons les rassembler en un seul fichier, il est temps d’automatiser la génération de la page HTML qui contiendra toute la documentation.\nPour cela, nous allons nous appuyer sur un plugin Maven : asciidoctor-maven-plugin.\nLa configuration à ajouter dans le fichier pom.xml \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.asciidoctor\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;asciidoctor-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2.1\u0026lt;/version\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;generate-docs\u0026lt;/id\u0026gt; \u0026lt;phase\u0026gt;prepare-package\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;process-asciidoc\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;backend\u0026gt;html\u0026lt;/backend\u0026gt; \u0026lt;doctype\u0026gt;book\u0026lt;/doctype\u0026gt; \u0026lt;attributes\u0026gt; \u0026lt;snippets\u0026gt;${project.build.directory}/generated-snippets\u0026lt;/snippets\u0026gt; \u0026lt;/attributes\u0026gt; \u0026lt;logHandler\u0026gt; \u0026lt;outputToConsole\u0026gt;true\u0026lt;/outputToConsole\u0026gt; \u0026lt;failIf\u0026gt; \u0026lt;severity\u0026gt;DEBUG\u0026lt;/severity\u0026gt; \u0026lt;/failIf\u0026gt; \u0026lt;/logHandler\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.restdocs\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-restdocs-asciidoctor\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-restdocs.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.jacoco\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jacoco-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${jacoco-maven-plugin.version}\u0026lt;/version\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;prepare-agent\u0026lt;/id\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;prepare-agent\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;generate-report\u0026lt;/id\u0026gt; \u0026lt;phase\u0026gt;verify\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;report\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; Ce code permet de générer une page HTML en piochant dans le répertoire target/generated-snippets, tout en bloquant le build en cas d’erreur rencontrée (snippet manquant, etc.).\nEn exécutant une commande comme mvn package, les tests seront exécutés, donc les snippets générés et finalement la page index.html sera créée à partir du fichier index.adoc. Et on peut la retrouver dans target/generated-docs.\nAperçu de la page HTML générée\rNous avons donc vu comment générer une page HTML décrivant les endpoints d’une application Spring Boot grâce à Spring REST Docs, sans refactorer tous les tests de controller.\nL’outil est assez complet et il resterait encore plein de petits détails à montrer pour être plus exhaustif. Mais je vous propose d’attendre un article présentant des bonus !\nLiens utiles :\nDocumentation de Spring REST Docs\nUn projet d’exemple fourni par Spring\nMon projet de démonstration\n","permalink":"https://alainnicolas.fr/fr/blog/make-documentation-great-again-part-2/","tags":["AsciiDoc","Spring REST Docs","Java","Spring Boot"],"title":"Make documentation great again (2/2)"},{"categories":null,"contents":" Vous aussi vous adorez les bandeaux de consentement que l’on trouve désormais sur (presque) tous les sites et vous rêvez d’en avoir un sur le vôtre ? C’est normal, ça fait tellement plus sérieux…​ Et puis, c’est aussi ça respecter les règles !\nRGPD, le vrai Cookie Monster Qu’est-ce qu’un cookie ? C’est un petit fichier assez simple déposé dans notre navigateur lorsque nous visitons certains sites. Notamment pour nous identifier lors de la prochaine visite. Ce qui peut parfois se révéler assez pratique : le site peut ainsi connaître à l’avance nos préférences d’affichage par exemple.\nMais lorsqu’une régie publicitaire commune à plusieurs sites se permet de tracer nos habitudes d’un site à l’autre, par exemple pour nous proposer des publicités sur Amazon en rapport avec nos pages Facebook suivies …​ l’aspect pratique s’efface derrière l’aspect effrayant. Nos données personnelles ne sont plus personnelles, alors même que l’on ne nous a pas demandé notre avis.\nC’est pour combattre cette dérive que le RGPD demande de recueillir le consentement des utilisateurs avant d’exploiter leurs données personnelles.\nRGPD : rappel rapide Le règlement général sur la protection des données est un texte du Parlement européen qui a pour but d’améliorer la protection des données des personnes, notamment en responsabilisant les acteurs du traitement de ces données.\nIl donne par ailleurs plus de pouvoirs aux autorités comme la CNIL, en charge de faire respecter les directives européennes transposées en droit français.\nLa conséquence Il en résulte une conséquence directe assez visible lorsque l’on navigue sur Internet : notre consentement autour des cookies est demandé à tout bout de champ.\nEt bien souvent la question est difficile à ignorer…​ Bandeau envahissant, popup au premier plan, tous les moyens sont bons pour détourner notre attention de l’information que l’on veut consulter. En améliorant la confidentialité de nos données, le RGPD a aussi considérablement détérioré notre expérience du web.\nLe RGPD ne se résume pas qu’au consentement autour des cookies, mais l’objectif ici n’est pas de lister les tenants et les aboutissants d’un texte de loi de plus de 80 pages.\nLa difficulté de faire les choses proprement Mais avant de jeter la pierre aux designers ou aux développeurs qui n’ont pas eu le choix, essayons de comprendre les difficultés qui résident dans la mise en œuvre du recueil du consentement des utilisateurs.\nLister les cookies La première étape consiste à lister les cookies utilisés par le site.\nBien souvent on retrouve un (ou plusieurs !) cookie(s) permettant la mesure d’audience, comme ceux déposés par Google Analytics ou ses concurrents. Mais il faut aussi penser à tous les services tiers utilisés…​\nC’est ainsi que sur le blog de Talan Labs dont j’évoque la création ici, nous utilisons par exemple Disqus pour gérer le système de commentaires.\nIl ne faut pas non plus oublier l’intégration de lecteurs vidéo comme YouTube qui apportent leur lot de cookies, l’utilisation de fonctionnalités de réseaux sociaux, etc.\nRendre les cookies optionnels Nous l’avons dit, de manière à être conforme aux recommandations de la CNIL, le site ne doit pas déposer de cookie sans le consentement du visiteur.\nCela signifie donc qu’il faut gérer 3 états :\nLe consentement n’a ni été donné, ni été refusé, donc les cookies ne doivent pas être déposés\nLe consentement a été refusé, donc les cookies n’ont pas été déposés et le site doit tout de même fonctionner normalement\nLe consentement a été accordé, donc les cookies peuvent être déposés\nIl faut donc à tout moment savoir si le consentement a été accordé et être capable de désactiver des fonctionnalités le cas échéant. Ce qui ne manque pas d’avoir un impact direct sur le code source de la page concernée…​\nOn se retrouve alors avec des petits morceaux de code retouchés qui ressemblent à cela :\nif (isGoogleConsentGiven) { // Add Google Analytics } if (isDisqusConsentGiven) { // Add Disqus } Ne pas (trop) dégrader l’expérience utilisateur On l’a vu plus haut, même en ayant refusé les cookies (ou en tout cas certains), l’utilisateur doit pouvoir continuer sa navigation le plus normalement possible. Il convient donc de vérifier que les fonctionnalités au cœur de notre page ne sont pas impactées par l’absence d’un service.\nPar exemple, une page qui liste des vidéos YouTube sous forme de vignettes …​ sans YouTube …​ ça rend tout de suite moins bien. Il faut donc à minima prévoir un petit message pour expliquer l’apparence surprenante de la page.\nDe plus, les bannières et autres encarts demandant le consentement viennent s’ajouter en superposition de pages souvent déjà bien remplies et complexifient parfois beaucoup trop la navigation. Même s’il y a du mieux ces derniers mois suite aux rappels à l’ordre de la CNIL, il est encore difficile de systématiquement refuser les cookies avec des boutons \u0026#34;ACCEPTER\u0026#34; bien trop mis en avant.\nAu-delà de l’aspect technique, il y a donc aussi des notions d’UX à prendre en compte pour éviter de retourner au web d’il y a 20 ans…​\nLa solution : tarteaucitron Nous l’avons vu, cette démarche de mise en conformité est donc relativement longue et complexe. Et heureusement, il est temps de présenter l’outil qui pourra grandement vous faciliter la tâche, Tarteaucitron !\nSans le savoir, il est probable que vous avez déjà utilisé Tarteaucitron, utilisé sur de nombreux sites (plus de 20 000 revendiqués sur le site de l’éditeur).\nC’est un outil qui se veut le plus générique possible, avec une version gratuite open-source et une version payante proposant une mise à jour continue ainsi qu’un plugin WordPress. Il consiste en une librairie JavaScript disponible via npm, autrement dit très facilement installable.\nIl convient alors de l’intégrer à votre page :\n\u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;/tarteaucitron/tarteaucitron.js\u0026#34;/\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; tarteaucitron.init({ // Configuration }); \u0026lt;/script\u0026gt; La configuration porte sur tous les aspects de l’outil : position de la bannière, affichage ou non des différents boutons de choix, etc. Il vous faudra vous retrousser les manches pour modifier l’apparence de la bannière, de l’icône et de l’écran de choix, mais rien de très compliqué.\nAperçu de la bannière sur ce site, en pied de page\rEnsuite, service par service, vous allez pouvoir remplacer votre intégration actuelle par celle de Tarteaucitron. Par exemple, dans le cas de Google Analytics, vous aviez l’habitude de l’ajouter comme ceci :\n\u0026lt;!-- Global site tag (gtag.js) - Google Analytics --\u0026gt; \u0026lt;script async src=\u0026#34;https://www.googletagmanager.com/gtag/js?id=UA-XXXXXXX\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag(\u0026#39;js\u0026#39;, new Date()); gtag(\u0026#39;config\u0026#39;, \u0026#39;UA-XXXXXXX\u0026#39;); \u0026lt;/script\u0026gt; Il faut désormais remplacer ce morceau de code par :\n\u0026lt;!-- Cookies management for Google Analytics --\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; tarteaucitron.user.gtagUa = \u0026#39;UA-XXXXXXX\u0026#39;; (tarteaucitron.job = tarteaucitron.job || []).push(\u0026#39;gtag\u0026#39;); \u0026lt;/script\u0026gt; À tout moment, l’utilisateur peut revenir sur ses choix, par défaut en cliquant sur l’icône située en bas à droite de l’écran comme sur ce site. Il accède alors à l’écran détaillé de choix :\nAperçu de l\u0026#39;écran de choix\rDe même, en naviguant sur le site, il peut se retrouver face à une fonctionnalité désactivée en l’absence de cookie, Tarteaucitron va automatiquement lui proposer d’accepter les cookies associés s’il veut s’en servir :\nAperçu d\u0026#39;une fonction de commentaire désactivée en l\u0026#39;absence de consentement autour de Disqus\rEn résumé, Tarteaucitron nous a permis de surmonter les difficultés listées plus haut :\nEn intégrant par défaut plus d’une centaine de services couramment utilisés, il permet de répondre à la grande majorité des cas que l’on peut lister sur son site\nIl gère le cas du consentement accordé au non, service par service\nIl évite de dégrader l’expérience utilisateur en proposant des bannières simples et en remplaçant proprement les encarts refusés\nPar sa facilité d’installation et de configuration, nul doute que Tarteaucitron continuera de gagner de nombreux utilisateurs dans les prochaines années …​ pour le plus grand bien des internautes !\n","permalink":"https://alainnicolas.fr/fr/blog/mettez-facilement-site-conformite-rgpd/","tags":["RGPD","Tarteaucitron","Blogging"],"title":"Mettez (facilement) votre site en conformité avec RGPD !"},{"categories":null,"contents":" Qui aime rédiger la documentation de son produit ou de son API ? Qui en a marre de trouver des documentations obsolètes en arrivant sur un projet ? Tu es développeur et tu te sens concerné ? Il est temps de passer à la \u0026#34;Documentation as Code\u0026#34; !\nIl est de coutume de documenter l’API que l’on développe, pour faciliter sa maintenance et les interactions avec ses \u0026#34;consommateurs\u0026#34;. Même si l’une des 4 valeurs de l’agilité promeut \u0026#34;un logiciel fonctionnel plutôt qu’une documentation exhaustive\u0026#34;, nous allons voir que l’on peut proposer les deux en même temps grâce à un outil particulièrement pratique.\n","permalink":"https://alainnicolas.fr/fr/series/make-documentation-great-again/","tags":null,"title":"Make documentation great again"},{"categories":null,"contents":" Qui aime rédiger la documentation de son produit ou de son API ? Qui en a marre de trouver des documentations obsolètes en arrivant sur un projet ?\nTu es développeur et tu te sens concerné ? Il est temps de passer à la \u0026#34;Documentation as Code\u0026#34; !\nLa documentation que tout le monde connait L’exemple le plus trivial de \u0026#34;Documentation as Code\u0026#34; est le traditionnel fichier README.md à la racine de tous les projets. Dans l’idéal, ce fichier contient la documentation minimale du projet, les instructions d’installation et peut-être même un descriptif des principales fonctionnalités.\nDans les faits, ce fichier est bien trop souvent négligé et rarement remis à jour. Et c’est bien dommage ! Comme il fait partie de votre projet, il est versionné et il n’y a pas besoin d’ouvrir un nouvel outil pour changer la documentation (Confluence ou SharePoint, on vous voit !).\nEt puis vous avez remarqué, par défaut, c’est un fichier .md, autrement dit en Markdown, un langage qui permet de formater du texte via des balises (définir un titre, mettre en gras, etc.).\nLogo Markdown\rL’énorme avantage : un humain peut le lire sans avoir le sentiment de lire du code (utile pour les parties prenantes non techniques d’un projet), mais en plus votre IDE ou GitHub peuvent l’afficher comme une page HTML bien présentée. Très pratique pour mettre à disposition du public votre documentation.\nUn pas en avant : l’AsciiDoc Mais parfois la documentation dépasse le simple texte et on a besoin d’afficher des tableaux : ils sont très mal gérés en Markdown. Un autre désavantage du Markdown : il ne donne pas de sens (sémantique) au contenu généré, autrement dit il faut insérer manuellement du HTML pour bénéficier de classes CSS ou de balises spécifiques.\nPour répondre à différents besoins qui ont émergé, des \u0026#34;flavors\u0026#34; de Markdown sont apparus. Autant de versions différentes, d’interpréteurs différents …​ et à la fin on a perdu le langage universel promis.\nC’est alors qu’intervient l’AsciiDoc. Comme le Markdown, c’est un langage de balises assez simple et lisible par un humain sans même être interprété. Mais il propose des balises pour afficher bien plus de types de données que le Markdown de base.\nLogo Asciidoctor\rUn autre avantage est la capacité à faire des \u0026#34;includes\u0026#34; d’un fichier dans un texte AsciiDoc. Par exemple, il est possible d’afficher le code présent dans un fichier du projet, et de voir ce morceau de code mis à jour dans la documentation à chaque modification du fichier source.\nPour les plus curieux, Asciidoctor propose une comparaison poussée entre Asciidoc et Markdown.\nUn exemple de document généré avec Asciidoctor Je l’évoquais l’an dernier dans un post, j’ai le plaisir d’encadrer des étudiants sur une série de cours autour des technologies Blockchain. Dans le cadre de ces cours, une grande place est laissée à la pratique, et même que l’on y parle de fromage…​\nExtrait du support d\u0026#39;un TP en PDF\rLes supports des TP sont régulièrement mis à jour, y compris pendant les séances lorsque les étudiants remarquent des erreurs ou ont besoin de plus de détails. Opération de mise à disposition qui serait bien plus lente dans le cadre d’un support rédigé sous Word par exemple, qu’il faudrait exporter en PDF manuellement, puis envoyer par mail, etc.\nDans notre cas, en demandant une génération en PDF et en HTML du support, et via un simple job de Gitlab CI, nous mettons à disposition en quelques instants la nouvelle version du support aux étudiants.\nMême extrait du support d\u0026#39;un TP, cette fois-ci en HTML\rEt si on faisait mieux ? OK, nous venons de voir qu’il existe un langage de balises pour formater du texte à but de documentation (voire de rédaction de livres !), plus évolués que Markdown …​ et surtout que LaTeX qui a d’autres intérêts, plus éloignés du monde de l’informatique.\nPour autant, il faut encore rédiger cette documentation, cela ne résout pas tous nos problèmes. Et si je vous disais que l’on peut aller plus loin ? La suite dans le prochain article !\nLiens utiles :\nDocumentation du langage AsciiDoc\nRésumé de la syntaxe\nAsciiDocLIVE, un éditeur AsciiDoc en ligne\n","permalink":"https://alainnicolas.fr/fr/blog/make-documentation-great-again-part-1/","tags":["AsciiDoc","Markdown"],"title":"Make documentation great again (1/2)"},{"categories":null,"contents":" Comme je l’ai déjà évoqué dans un post précédent, le partenariat entre Talan et l’EPF m’a fait découvrir le rôle du formateur. Mais nous sommes allés plus loin, en proposant un projet sur le long terme à un groupe d’étudiants de 5ème année.\nDes attentes qui se rejoignent Avant le grand saut dans la vie active en passant par le stage de fin d’études, les étudiants doivent se confronter au monde de l’entreprise au travers d’un projet de 5 mois. Entre le projet scolaire et le projet réel, il s’agit là de mettre en pratique les connaissances acquises, mais aussi de découvrir les « vraies » méthodes de travail de l’entreprise.\nPromo 2020 dans sa salle @ Talan — 16/10/2019\rÉvidemment, ces attentes pédagogiques ne pouvaient que nous intéresser, puisque cela nous permet de nous frotter nous-mêmes aux problématiques soulevées par un projet blockchain tel que nous n’avons pas toujours le temps de mettre en place le reste du temps.\nPour cela, il nous fallait nous éloigner d’un projet trop scolaire, autrement dit « jetable », pour nous concentrer sur un sujet à même de mobiliser aussi bien nos équipes que les étudiants.\nLe projet Share2Gether Contrairement au TP de création d’un système de vote réalisé sur une journée tel que nous avons pu le mettre en place lors de la formation initiale, nous voulions un projet beaucoup plus complet et long terme. Et parce qu’utiliser une technologie comme la blockchain juste pour l’utiliser n’a pas vraiment de sens, il nous fallait imaginer un cas d’usage plausible.\nC’est ainsi qu’est né le projet Share2Gether, visant à proposer une solution d’organisation d’événements, à l’image de ce que propose Meetup.com. En effet, lors de l’accueil de différents meetups dans nos locaux, nous avons été régulièrement confrontés au « no-show », autrement dit à des inscrits qui ne viennent pas à l’événement, sans prendre la peine de libérer leur place.\nMeetup blockchain @ Talan — 29/05/2019\rSi ce comportement est connu des organisateurs, il n’en est pas moins frustrant, soulevant notamment des problématiques de gâchis alimentaire lors la commande de buffet ou empêchant des personnes qui le souhaite réellement de venir et trouvant des événements notés complets à tort. Avec un absentéisme de 20 à 50 %, tous les types d’événements sont concernés, y compris les meetups orientés blockchain.\nAu travers d’un système de réputation, et donc de bonus / malus, nous souhaitons encourager les inscrits à venir ou tout au moins à favoriser les désinscriptions pour donner une lecture claire à l’organisateur du nombre de participants.\nUne organisation à imaginer À partir de l’idée du produit, on imagine très vite une implémentation technique, les technologies à utiliser, etc. Mais encore faut-il faire passer ces idées aux étudiants et surtout leur donner envie de s’approprier le projet.\nConvaincus des valeurs défendues par Talan Labs quant aux méthodes de travail (solidarité, amélioration continue, etc.), il était naturel d’en profiter pour transmettre les préceptes de l’agilité à l’équipe qui se formait tout juste.\nMais la méthode ne fait pas tout ! Lors de la première année du projet nous avons découvert au fur et à mesure que certaines notions fondamentales n’étaient pas abordées dans le cursus académique des étudiants. Design thinking, gestion du code source, tests automatisés, les sujets étaient nombreux et variés, et ont nécessité des formations ciblées en cours de projet, principalement à la demande des étudiants eux-mêmes.\nPromo 2020 dans sa salle @ Talan — 16/10/2019\rDe manière à anticiper ces questions lors de la deuxième année du projet, nous avons proposé aux étudiants de la promo 2020 de suivre ces formations dès le début. Évidement, de la théorie de « il faut écrire des tests » à la mise en pratique pendant le développement, il y a un pas important à franchir. Pour autant, l’idée même de l’aspect indispensable des tests était ancrée dès le commencement.\nUne fois les bases acquises, la routine peut se mettre en place, rythmée par les réunions agiles. Tous les mercredis, les étudiants bénéficient d’une salle qui leur est réservée, mais peuvent facilement solliciter les collaborateurs Talan Labs présents sur les plateaux autour. C’est cette proximité qui permet aussi d’apercevoir le quotidien d’un développeur et la vie d’une équipe projet.\nDe la « galère » à la maîtrise Ces deux années de projet ont partagé des caractéristiques, à commencer par une première période compliquée pour les étudiants. Des nouveaux langages, des technologies nouvelles, une méthode de travail à laquelle on n’est pas habitués …​ autant d’obstacles à surmonter.\nPromo 2020 dans sa salle @ Talan — 16/10/2019\rC’est sûrement là la valeur principale que nous avons voulu transmettre : même en manquant de confiance en eux, même en doutant des enseignements de l’école, les étudiants sont capables de travailler « pour de vrai » et de créer de la valeur. En fin de projet, les retours des étudiants étaient sans équivoque :\nIls étaient heureux du résultat obtenu et quasiment étonnés d’avoir réussi à autant produire.\nAvec le recul, nous pouvons dire que nous ne nous attendions pas à ce retour. Nous comptions former des étudiants en leur apportant des compétences nouvelles, mais ce qui a le plus fait la différence est bien la confiance transmise. Avant de maîtriser les nouvelles technologies comme la blockchain, l’ingénieur de demain doit avoir confiance en ses capacités (et notamment ses capacités à apprendre et découvrir).\nUne présentation réussie …​ et le tour est joué ! Que serait un projet scolaire sans sa soutenance finale ? Il nous paraissait important de cultiver ces compétences oratoires au même titre que les compétences techniques, c’est pour cela que nous avons proposé aux étudiants plusieurs présentations « à blanc » de leur soutenance.\nPromo 2020 lors d’une présentation “à blanc” @ Talan — 15/01/2020\rD’abord entre nous pour identifier les points attendus par l’école et les principaux messages à faire passer. Puis, face à quelques collègues qui n’ont pas suivi le projet dans ses détails, mais qui vont pouvoir identifier les messages trop survolés tandis que les designers vont se charger de conseiller sur le support en lui-même.\nNouveauté cette année comme nous avions du temps en fin de projet : une présentation à des Directeurs Talan. Notre DRH, notre Directrice de la Communication ou encore le Directeur Général de Talan Labs ont pu assister à la présentation des étudiants. Et quelle présentation ! Si l’ingénieur généraliste EPF a bien une force, c’est celle de savoir transmettre ses messages avec conviction et clarté, parfois même avec humour.\nPromo 2020 lors de la présentation finale @ Talan — 22/01/2020\rForts de cette expérience qui était de leur propre aveu plus stressante que les présentations habituelles, les étudiants ont pu délivrer une soutenance finale de grande qualité à leurs professeurs et encadrants. Deux ans de suite j’ai eu le plaisir de voir les groupes encadrés réussir leur soutenance et montrer une joie non feinte en évoquant le travail fourni.\nUne suite prometteuse Entre les formations délivrées en 4e et 5e années (évoquées dans un post précédent) et le projet Share2Gether, l’investissement réalisé par Talan Labs est important, mais évidemment pas dénué d’intérêt. En montrant nos compétences et notre état d’esprit, en apportant de la confiance et des connaissances aux étudiants, nous souhaitions aussi leur donner envie de nous rejoindre.\nC’est donc avec plaisir que nous comptons désormais dans nos rangs de nouveaux ingénieurs EPF (du stage de fin d’études au CDI). Et nous ne comptons pas nous arrêter là : les années à venir seront tout aussi chargées !\nRetrouvez l’article présentant la formation Blockchain délivrée à l’EPF depuis 2018 et l’ensemble des articles sur le thème de la #blockchain !\n","permalink":"https://alainnicolas.fr/fr/blog/blockchain-projet-scolaire-monde-entreprise/","tags":["Blockchain","EPF","Formation"],"title":"Blockchain : du projet scolaire au monde de l’entreprise"},{"categories":null,"contents":" Depuis deux ans j’ai la chance et le plaisir d’intervenir auprès des étudiants de l’EPF, école d’ingénieurs généraliste dont j’ai été diplômé en 2015. Passer de l’autre côté de l’enseignement n’est pas une mince affaire, surtout sans expérience, mais revenir dans «son» école facilite largement le changement de posture.\nUne école d’ingénieurs a la lourde responsabilité de maintenir sa formation à jour, pour préparer les étudiants du mieux possible à leur entrée dans le monde du travail. C’est ainsi que Talan a développé un partenariat avec l’EPF, pour un cycle de formations sur le thème de la Blockchain pour ses 4ème et 5ème années de la filière informatique.\nFaire passer ses idées Notre premier challenge était de créer une formation théorique. Travailler sur cette technologie relativement jeune et aux applications disruptives apporte des convictions et des idées fortes sur ce que la blockchain peut faire, mais aussi et surtout sur ce qu’elle ne peut pas faire. Les implications de la mise en place d’un tel système distribué ont plus d’impacts sur les organisations et les personnes que la technologie en elle-même sur les systèmes d’information. Pour autant, face à un public étudiant, il convient de regarder de près les composantes techniques de la blockchain pour en saisir l’intérêt.\nDe nombreuses idées à faire passer, sur des thèmes très vastes et variés, de la plus petite brique technique à la conduite du changement, en passant par des concepts complexes, la gouvernance…​\nFormaliser et organiser ces idées en thèmes, les articuler de manière logique et fluide, en détaillant les concepts sans forcément entrer trop en détails dans l’implémentation, s’adapter aux connaissances supposées d’étudiants que l’on ne connaît pas…​ Autant de challenges à relever, mais non sans intérêt : c’est bel et bien le meilleur moyen de se rendre compte des concepts que l’on maitrise et de ceux qui méritent que l’on s’y attarde.\nDéfinition d\u0026#39;une blockchain en 5 mots\rGrâce à de nombreuses présentations « à blanc » du support face aux collègues, on fait émerger les questions qui subsistent, les passages trop rapides sur des points complexes et, surtout, il devient possible de roder une première version du discours qui se doit de rester interactif et illustré pour intéresser.\nDu baptême du feu au discours rodé Après une première édition de la formation en conditions réelles, face à des étudiants qui semblent intéressés et posent des dizaines de questions, nous ne comptions pas en rester là. L’objectif était de passer d’une formation basique à un parcours complet couvrant plusieurs technologies de Blockchain et DLT, à destination de nos clients.\nIl est clair qu’une formation sur un sujet aussi mouvant doit rester vivante et évolutive, même si cela suppose un investissement constant.\nFormation théorique @ EPF — 04/06/2019\rC’est ainsi que les étudiants de la promotion 2020 ont bénéficié d’une formation largement revue, telle que nous la délivrons à nos clients ou lors de BBL.\nPour éviter la perte de spontanéité et la routine, j’essaye de changer au moins un slide par présentation, de toujours adapter le contenu au public ou à la durée, voire de prendre des angles très différents, comme à l’https://www.esgi.fr/[ESGI^] (une école d’informatique) où le thème était « Blockchain : des métiers pour tous ».\nAdapter son discours au public est indispensable : face à un public très haut niveau et fonctionnel on survole les aspects techniques, tandis que face à des développeurs il convient souvent de descendre dans les entrailles de la blockchain, pour évoquer les algorithmes de consensus, etc.\nDe la théorie à la pratique, il n’y a que la création d’un TP Sans en avoir la consigne directe de la part de l’EPF, nous souhaitions limiter le temps de présentation théorique pour accorder du temps à la pratique.\nDe manière à rester relativement abordables et en accord avec une idée de réelle décentralisation, nous avons choisi dans un premier temps de nous concentrer sur Ethereum, probablement la blockchain la plus accessible.\nMais par où commencer ?\nCryptoZombies Nos premières expérimentations sur Ethereum remontent à fin 2016, avant qu’un écosystème ne se mette parfaitement en place. Mais en gardant un œil sur les nouveautés nous ne pouvions rater la franche réussite de CryptoZombies, sûrement le meilleur moyen de découvrir le langage Solidity des smart contracts Ethereum.\nCryptoZombies a été créé par Loom Network afin de rendre plus facile l’apprentissage de Solidity. Persuadés de leur pertinence, nous estimons qu’il faut faire profiter de ces excellents exercices à nos étudiants. Au-delà de la facilité que cela représente pour nous, il faut reconnaitre que CryptoZombies est bien pensé et surtout très ergonomique, il serait dommage de créer une formation dédiée alors que la communauté s’accorde à l’utiliser.\nEn créant une armée de zombies, les étudiants acquièrent les bases techniques du développement de smart contracts, il est ensuite temps de passer aux choses encore plus sérieuses !\nVote décentralisé Pour le saut dans le grand bain, nous avons choisi de mettre en place un TP visant à développer une application de vote décentralisée.\nDe manière à ne laisser personne en chemin, mais aussi pour faciliter l’encadrement de ce TP, nous avons choisi de rédiger un support le plus complet possible, ainsi que de proposer un jeu de tests unitaires qui valident étape par étape les développements.\nPage de garde du support de TP\rCette préparation en amont est loin d’être anodine, et s’est déroulée sur plusieurs semaines :\nRéalisation du système de vote minimal (possibilité de créer une élection avec des candidats et de voter pour l’un d’entre eux à chaque élection) et validation des développements par des tests unitaires\nRédaction d’un premier jet du support, basé sur des souvenirs des développements qui venaient d’avoir lieu\nRéalisation du TP par 10 de nos collègues, sur la base du support uniquement, afin d’obtenir un maximum de retours\nCorrection et amélioration du support, mais aussi des exercices à réaliser (trouver la bonne balance entre le guidage total et l’incompréhension des consignes, établir la liste exhaustive des pré-requis, etc.)\nNouveaux tests en conditions quasi-réelles, etc.\nEt puis le jour J arrive. Une soixantaine d’étudiants doivent suivre nos instructions, à commencer par la mise en place du poste de développement. Et c’est bien là que les premières difficultés apparaissent.\nTP @ EPF — 04/06/2019\rÉvidement, sur le PC d’un développeur, la majorité des pré-requis est déjà présente (variables d’environnement maîtrisées, outils installés et maîtrisés, etc.). Mais sur des postes aux performances et systèmes d’exploitation variables, avec des niveaux de maîtrise très hétérogènes et des consignes parfois survolées, les premières salves de questions surprennent. Tout ce qui nous paraît évident ne l’est pas pour tout le monde, c’est bien là notre première leçon. Ce qui nous paraît complexe ne l’est pas pour tout le monde non plus, et c’est là notre meilleure surprise.\nSi nous attendions des difficultés dans la compréhension et la rédaction des smart contracts par exemple, le gros des problématiques rencontrées est finalement au niveau de leurs appels depuis une page web. Ces notions de smart contracts et leur langage (Solidity) ont beau être relativement novatrices, pour des débutants le développement web l’est tout autant.\nRetour d’expérience Nous étions venus pour transmettre des connaissances, mais aussi pour bénéficier des enseignements que des étudiants ont à transmettre. En mettant en place un climat de confiance (facilité lorsque l’on sort de la même école), il devient possible de récolter des avis francs et des idées d’amélioration au plus près du terrain.\nSur ces journées de formation, si la balance théorie / pratique a paru bonne, les difficultés rencontrées dans le développement web ont plombé le ressenti des étudiants.\nNul doute que nous prenons en compte ces problèmes pour tenter de les effacer lors de la prochaine session. Par exemple en fournissant plus de tests unitaires qui guident de manière plus stricte, ou une interface web attrayante plus satisfaisante pour tous.\nRetrouvez la vidéo de présentation de ces formations auprès des étudiants de l’EPF réalisée par Talan :\nAu-delà de ces formations ponctuelles de quelques jours en 4e et 5e années, Talan Labs s’est aussi lancé dans l’accompagnement d’un groupe de projet plus restreint (5 en 2018/2019 puis 8 en 2019/2020), toujours sur la thématique de la blockchain.\nC’est l’objet d’un autre article !\nCet article a initialement été publié sur Medium.\n","permalink":"https://alainnicolas.fr/fr/blog/blockchain-former-les-ingenieurs-de-demain/","tags":["Blockchain","EPF","Formation"],"title":"Blockchain : former les ingénieurs de demain"},{"categories":null,"contents":" Depuis plusieurs années, j’ai la chance d’intervenir auprès des étudiants de l’EPF. Passer de l’autre côté de l’enseignement n’est pas une mince affaire, surtout sans expérience…​ Le partenariat avec l’EPF m’a fait découvrir le rôle de formateur. Nous sommes allés plus loin, en encadrant un groupe d’étudiants sur un projet durant tout un semestre.\nRetour d’expérience sur des journées pas comme les autres !\n","permalink":"https://alainnicolas.fr/fr/series/formation-blockchain-epf/","tags":null,"title":"Formation Blockchain à l'EPF"},{"categories":null,"contents":" Nous avons vu la présentation des grands principes de Corda, le DLT (Distributed Ledger Technology) développé par le consortium R3. Utilisé en très grande majorité par des banques, Corda semble répondre à de nombreux besoins non assouvis par les blockchains publiques. Nous allons désormais tâcher d’explorer les limites de Corda.\nEst-ce que c’est une blockchain ? À question directe …​ réponse directe : non. Corda n’est pas une blockchain.\nOk, mais, pourquoi ? Tout simplement parce que le registre Corda n’est pas stocké sous forme de blocs, donc pas de chaîne de blocs possible.\nMais alors, si ce n’est pas une blockchain, ce n’est pas intéressant ? C’est beaucoup plus compliqué que ça…​\nCertes, ces deux dernières années, le mot ‘blockchain’ fait le buzz, y compris dans les médias généralistes, notamment suite à l’envol de la valeur de certaines crypto-monnaies. Pour autant, pour l’immense majorité des entreprises et tout particulièrement des banques, tout ce qui touche aux crypto-monnaies est bien loin de leurs intérêts premiers, et on parle plus volontiers de DLT (Distributed Ledger Technologies). Les DLT forment un ensemble de technologies qui englobent les blockchains, bien plus large que simplement Bitcoin ou Ethereum.\nPour autant, la communication autour de Corda, principalement par le consortium R3, a entretenu un certain flou sur la question depuis les origines. Et ce flou perdure ! Lorsque l’on se rend sur le site officiel de Corda, la baseline du logo est claire :\nCapture d’écran du site corda.net\rPour autant, la polémique ne date pas d’hier, puisque déjà en 2017 R3 publiait un post sur son blog pour expliquer que le problème est plus de l’ordre de la sémantique que de l’architecture. Il semblerait donc que le terme de ‘blockchain’ soit ici utilisé comme un raccourci pour ‘DLT’, avec une composante marketing indéniable. #buzzword\nEst-ce que Corda est décentralisé ? Comme nous l’avons vu dans l’article de présentation, pour rejoindre un réseau Corda il faut fournir son identité à un doorman qui autorise l’accès et fournit les certificats nécessaires. Ce doorman peut révoquer une identité (dans le cas du retrait d’un participant au sein d’un consortium par exemple). Mais ne serait-ce pas là une porte ouverte à la censure ?\nTout dépend de qui gère ce service central. R3 a récemment annoncé la création de la “Corda Network Foundation”, une entité à but non lucratif en charge de gérer le réseau mondial Corda. Donc une seule entité va être chargée de gérer un réseau soi-disant décentralisé…​ Heureusement, l’aspect non lucratif garantit une certaine résilience à la corruption par exemple.\nPour autant, si l’on craint une certaine centralisation du ‘pouvoir’, il est toujours possible de créer son propre réseau privé, avec sa propre gouvernance et ses propres règles. Donc inutile de paniquer, la solution existe.\nEst-ce que Corda est réellement open-source ? Il existe deux versions de Corda : la version Community, totalement open-source et dont le code est disponible sur GitHub, et une version Enterprise, pour laquelle il faut un compte R3 pour obtenir les exécutables.\nIl s’agit là d’une différence majeure : on récupère des exécutables et non pas du code source. Même en considérant que la majorité du code de “Corda core” est similaire dans les deux versions, la brique “firewall”, argument principal justifiant la valeur de la version Enterprise, est totalement opaque. Difficile de savoir comment est assurée la sécurité via ce firewall…​\nA quoi servent les notaires de Corda ? Actuellement, les nœuds de type ‘notaire’ d’un réseau Corda proposent deux modes : *validating *et non-validating. Lorsqu’ils sont non-validating, ils ne procèdent qu’à une seule vérification : la double dépense. En revanche, en mode validating, le notaire va inspecter le contenu de la transaction pour le valider, selon le protocole de consensus choisi (RAFT ou BFT disponibles).\nToutefois, sur le réseau d’UAT fourni par R3, seul le mode non-validating est actuellement disponible, ce qui diminue l’intérêt des notaires. Cela s’explique par des besoins de performances qui ne semblent donc pas encore au rendez-vous avec le mode de fonctionnement cible.\nÀ noter que les notaires jouent tout de même un rôle intéressant en étant des témoins supplémentaires des transactions, notamment en permettant d’horodater de manière univoque celles-ci.\nIntégration dans un système d’information legacy Corda étant vendue comme une solution tournée vers les entreprises, tout laisse à penser que son intégration a été prévue pour s’imbriquer sans souci dans le SI des grandes banques qui constituent le consortium R3. Malheureusement, la réalité n’est pas aussi rose…​\nAlors évidemment, la notion même de peer-to-peer est antinomique de ce que font les banques. Par exemple, pour convaincre les équipes de sécurité d’accepter de nouveaux flux considérés comme ‘exotiques’ dans leur SI, il est nécessaire de travailler de concert dès le lancement des initiatives Corda.\nUne fois les validations obtenues via les équipes d’architecture technique et de sécurité, encore faut-il s’attaquer à la réalisation technique. Malheureusement, la documentation de Corda n’est pas parfaitement autoporteuse. De nombreux allers-retours sont nécessaires avec les équipes de support et de déploiement de R3.\nPar exemple, si un flux n’est pas documenté par R3, l’impact temporel sur un déploiement peut être assez conséquent : toutes les étapes de documentation, de validation et de mise en pratique sont parfois longues.\nPour autant, Corda reste une solution très tournée vers le monde des entreprises sécurisées. Évoquons notamment Hyperledger Fabric qui utilise des flux gRPC (Remote Procedure Call, développé initialement par Google), alors qu’il n’y a actuellement pas de WAF (Web Application Firewall, chargé de protéger le serveur applicatif) en mesure d’analyser ces flux qui contiennent de surcroit de nombreuses failles CVE identifiées. Idem par rapport à Quorum qui ne comporte pas de brique firewall, donc avec tout le traitement dans la même zone réseau.\nConclusion(s) et ouverture(s) En guise de conclusion, précisons tout de même que le but n’était pas de critiquer unilatéralement cette solution, mais bien d’examiner des axes d’amélioration ou des contradictions dans la communication officielle.\nSi Corda est une solution DLT encore jeune et prometteuse, elle n’en a pas moins de nombreux challenges à relever. Améliorer son intégration aux SI existants, avoir une documentation à jour, clarifier sa nature (blockchain vs. DLT) …​ les pistes sont nombreuses !\nDe plus, pourquoi ne pas aller un cran plus loin et imaginer une solution interopérable avec d’autres DLT, pour devenir une brique incontournable d’un système décentralisé ? Si les blockchains actuelles ne sont pas interopérables, Corda aurait tout à y gagner, pour se démarquer plus fermement sur un marché (déjà) concurrentiel.\nLa documentation a été pointée comme lacunaire, toutefois il faut noter un effort certain de transparence avec la page “Tradeoffs” qui liste les points sur lesquels des concessions ont été faites. Parmi ces concessions, on relèvera un point : R3 encourage à doubler les contrats en code par des contrats sur papier. Un comble pour une solution censée désintermédier les échanges de ses participants ! En opposant “Code is law” et “Existing legal systems”, R3 trahit en fait une réalité : les entreprises et les réglementations en vigueur ne sont pas encore prêtes à reposer uniquement sur du code.\nSi le produit n’est pas fini, avec une roadmap encore floue, il n’en est pas moins en constante (r)évolution, réagissant aux demandes de ses clients, grâce à une équipe de développeurs très investis, réactifs et heureux d’échanger avec les utilisateurs finaux.\nAu-delà des difficultés initiales, Corda devrait réussir à repousser ses limites et s’assurer un avenir plus radieux dans le monde bouillonnant des blockchains et DLT !\nCet article fait partie d’une série sur Corda, commencée par R3 Corda : Présentation.\nCet article a initialement été publié sur Medium.\n","permalink":"https://alainnicolas.fr/fr/blog/r3-corda-limites/","tags":["Corda","R3","DLT"],"title":"R3 Corda : Limites"},{"categories":null,"contents":" Les technologies Blockchain \u0026amp; DLT (Distributed Ledger Technology) sont nombreuses. Nous allons ici nous concentrer sur Corda, un DLT développé par le consortium R3.\nGenèse du projet À l’origine de Corda : cinq problématiques des blockchains publiques les rendent inadaptées à l’utilisation en entreprise. Nous allons commencer par détailler ces problématiques.\nManque de confidentialité Les blockchains classiques telles qu’Ethereum proposent un registre complet distribué entre tous les participants (les ‘nœuds’). Or, pour des raisons de compétition voire de régulation, il est difficilement envisageable de donner accès à toutes les transactions réalisées par une entreprise à ses concurrents directs.\nRisque de non-finalité R3 considère que le protocole PoW (Proof of Work) utilisé par Bitcoin ne répond pas au besoin de ‘finalité’ requis par les entreprises. En effet, pour entériner une transaction dans le registre, il faut attendre le travail des mineurs, et même si la transaction est ajoutée à un bloc, rien ne permet de s’assurer définitivement qu’un fork n’aura pas lieu.\nPseudonymat des participants Si l’inscription sur un réseau tel qu’Ethereum est très facile, par exemple en créant son portefeuille via MyEtherWallet, à aucun moment dans le processus il n’est demandé de fournir son identité. Alors, anonymat complet ? Non, pas complètement. À travers des pratiques de crawling on peut assez aisément relier de nombreuses adresses de portefeuilles à des individus précis. On parle de ‘pseudonymat’.\nLorsque l’on parle d’échanges entre des entreprises, il est évident qu’elles doivent savoir à tout moment à qui elles ont affaire. Plutôt que de masquer l’identité des participants, il faut bien au contraire identifier fortement les entités qui traitent sur le réseau.\nFaible scalabilité On recense plusieurs milliards de transactions de type ‘paiement’ dans le monde chaque jour. À l’inverse, Bitcoin ne traite qu’environ 300 000 transactions dans une journée. Pour qu’un système actuel puisse être remplacé par un système blockchain, il faut que ce dernier puisse absorber autant de transactions. Ce critère est d’autant plus important en entreprise que la rapidité de transfert est parfois indispensable (par opposition de la moyenne actuelle de 19 secondes par bloc sur Ethereum).\nFaible productivité et lenteur d’intégration Si les technologies et langages exotiques comme Solidity (pour Ethereum) sont loin de rebuter les startups, il est clair qu’un grand compte (une grande banque, un assureur, etc.) aura plus de mal à accepter l’ajout d’une brique d’un nouveau format dans son système d’information. De plus, il est aujourd’hui plus facile de recruter des développeurs Java que Solidity…​\nPénurie des talents et standardisation du SI poussent les entreprises à privilégier des technologies déjà éprouvées plutôt que les nouveautés encore mal maîtrisées voire interdites par les experts de la sécurité.\nHistorique rapide C’est sur la base de ces observations communes à plusieurs acteurs financiers que consortium R3 est fondé en 2015 par des grandes banques du monde entier, comme Barclays, Société Générale ou Deutsche Bank. La première version officielle de Corda sort en octobre 2017, avant une version d’entreprise en juillet 2018.\nCorda est présentée comme étant une ‘blockchain’ d’entreprise, mais nous aurons l’occasion de revenir sur la notion de ‘blockchain’ dans ce cas précis. R3 part du constat que les solutions comme Ethereum ou Bitcoin ne répondent pas aux besoins spécifiques d’une entreprise.\nDeux versions de Corda Corda se décline en deux versions, chacune dédiée à un usage différent.\nCommunity Edition Version open-source de Corda, accessible à tous et dont le code source est disponible sur GitHub.\nUn très bon moyen de se former aux concepts de base, créer sa première CorDapp (application Corda, par analogie aux ÐApps d’Ethereum — applications décentralisées). Pour cela, la documentation de Corda propose des tutoriels qui permettent assez rapidement de faire fonctionner un réseau Corda, de développer des contrats et faire des transactions.\nEnterprise Edition Version dédiée aux entreprises, accès aux exécutables avec un compte.\nCette version entend répondre plus spécifiquement aux besoins des entreprises. C’est ainsi qu’elle permet de coller aux exigences de haute performance et haute disponibilité, propose un support de plusieurs bases de données (Oracle, SQL Server, etc.) et une migration d’un système à l’autre.\nMais surtout, cette version inclut un composant supplémentaire : le firewall. Élément à l’aspect marketing indéniable, surtout en pensant à des contextes très sécurisés comme dans une banque. Composé de deux éléments (bridge \u0026amp; float), il entend garantir la qualité des données en entrée et sortie du SI.\nQuelques concepts de base Un réseau sous contrôle Un réseau Corda est semi-privé, dans la mesure où chaque nœud doit fournir des éléments permettant de justifier de son identité à un doorman pour rejoindre le réseau. Ce service permet de s’assurer que chaque entité participant au réseau est connue de manière non ambigüe. On parle alors d’un processus de KYC (Know Your Customer), largement répandu dans de nombreuses activités hors blockchain.\nUn réseau Corda est donc composé de nœuds et d’un doorman, mais aussi d’un ou plusieurs service(s) de notaire. Un notary est un nœud particulier, chargé de garantir l’unicité des mises à jour du registre.\nUne fois validée par le doorman, l’identité d’une entité est attestée par un certificat X.509 délivré par celui-ci, et publiée sur l’ensemble du réseau via un service dit de network map.\nUn registre semi-partagé Contrairement à Ethereum où tous les participants ont accès au registre de toutes les transactions, le registre de Corda n’est pas entièrement partagé. En effet, un nœud n’a accès qu’aux données pertinentes pour son activité. C’est ainsi que sur le schéma ci-dessous, le nœud Alice n’a pas accès aux données partagées entre Bob et Carl alors même qu’il partage certaines informations avec Bob.\nReprésentation d’une partie du registre © R3 Limited\rDe plus, Corda va synchroniser en continu les données partagées par deux nœuds. Ainsi, nous avons l’assurance qu’à tout moment Alice et Bob voient la même chose.\nReprésentation de la synchronisation des données entre deux nœuds © R3 Limited\rDes ‘états’ propres aux nœuds Chacun des points de couleurs des schémas ci-dessus représente un fait, un ‘état’. Les states d’un nœud peuvent évoluer dans le temps. Pour réaliser cette évolution, l’état courant est marqué comme ‘historique’ et un nouvel état mis à jour est créé. L’ensemble des états, y compris leurs versions historiques, est stocké dans un vault propre à chaque nœud. Ce coffre-fort ne contient donc que les états relatifs au nœud.\nEn rentrant un peu plus dans les détails, ce vault est en réalité une base de données classique (par défaut H2 pour la version Community, avec possibilité de passer sur des systèmes plus complets comme Oracle avec la version Enterprise). Nous sommes donc bien loin d’une blockchain puisque la notion même de ‘bloc’ est totalement absente de Corda. C’est notamment cette architecture radicalement différente qui permet d’assurer de meilleures performances de transaction.\nAutomatisation via des contrats Si vous avez déjà approché Ethereum, vous avez entendu parler des smart contracts. Ces bouts de code qui n’ont d’intelligent que le nom permettent l’automatisation de certaines tâches lors de transactions avec la blockchain.\nCorda n’échappe pas à ce concept, en le nommant plus sobrement ‘contrat’. Les contrats Corda sont rédigés dans des langages exécutables par la JVM (Java Virtual Machine), Java et Kotlin en tête. C’est ainsi qu’un développeur Java ‘classique’ pourra s’approprier un contrat Corda assez facilement, sans apprendre un nouveau langage, uniquement en exploitant l’API fournie par Corda.\nL’exécution d’un contrat doit être ‘déterministe’, dans la mesure où l’acceptation d’une transaction par le contrat dépend uniquement du contenu de celle-ci.\nDes transactions sous conditions Nous venons tout juste d’évoquer le terme de ‘transaction’, il est temps de le définir. Une transaction est avant tout un souhait de mettre à jour le registre. Ce souhait ne peut ensuite être entériné dans le registre qu’à trois conditions :\nElle ne contient pas de ‘double dépense’ (autrement dit elle n’essaye pas de consommer un état déjà consommé)\nElle respecte les termes du contrat Corda (nature des paramètres d’entrée, etc.)\nElle a été signée par les parties requises\nDes flows pour atteindre le consensus Entre l’émission du souhait de mettre à jour le registre et sa prise en compte par les nœuds impliqués, il y a donc plusieurs étapes, qui peuvent paraître lourdes et redondantes, là où une blockchain classique se charge entièrement de traiter la transaction émise.\nC’est là que la notion de flow entre en jeu. Les flows Corda visent à automatiser le processus de consensus. Fort heureusement, il n’y a pas besoin de développer les mêmes flows de manière répétitive, car Corda fournit par défaut des flows standardisés pour les actions courantes (signature de transaction, vérification d’un ensemble de transactions, etc.).\nValidité des transactions en deux volets Comme nous l’avons vu, pour être intégrée au registre, une transaction doit répondre à des règles précises et inaltérables. Ces règles ont deux pendants :\nValidité Les entités devant signer une transaction vérifient sa validité avant d’apposer leur signature. Pour cela, les inputs et outputs de la transaction doivent répondre aux règles pré-établies, ainsi que toutes les transactions antérieures ayant amené au state que nous essayons de modifier. On peut donc parler de ‘chaînage’ des transactions même si on est loin du fonctionnement d’une blockchain.\nUnicité Une transaction ne doit pas consommer un état qui a déjà été consommé. Par exemple, une entité ne doit pas pouvoir dépenser de l’argent qu’elle a déjà donné à une autre entité. Donc, les inputs de la transaction ne doivent pas avoir été historisés auparavant.\nLe cœur de Corda : le nœud Un nœud Corda est une instance de JVM possédant une identité unique au sein d’un réseau. Il possède deux interfaces avec l’extérieur :\nUne couche réseau pour interagir avec les autres nœuds\nUne interface RPC pour interagir avec son propriétaire\nComme nous l’avons vu, un nœud contient aussi son vault qui contient les states et un service de stockage pour héberger les transactions et leurs éventuelles pièces jointes.\nTel quel, le nœud permet donc des opérations basiques, mais ses fonctionnalités sont évidemment restreintes et doivent être étendues par l’ajout de CorDapps.\nL’application distribuée : la CorDapp Une CorDapp est une application distribuée sur un réseau Corda, à l’image des ÐApps sur un réseau Ethereum. Elles sont constituées de :\nstates qui définissent les ‘faits’ manipulés par la CorDapp\ncontracts qui définissent les règles de validation de transaction à appliquer\nservices qui fournissent des méthodes utilitaires pour interagir avec les composants du nœud\nwhitelists qui imposent les données que le nœud peut recevoir.\nContrairement à un réseau Ethereum, la CorDapp ne sera pas propagée dans tous les nœuds du réseau, mais installée de manière optionnelle sur les nœuds volontaires. Tant qu’un nœud n’a pas la CorDapp ad hoc pour exécuter un certain flow, il ne pourra pas l’exploiter.\nPour aller plus loin…​ Nous avons évoqué de nombreux concepts à la base de Corda et de ses composants, mais il est évident que de nombreux détails pourraient être ajoutés. La documentation officielle de Corda pourra sûrement répondre aux questions plus poussées !\nDans un prochain article, nous évoquerons les limites de Corda pour garder un regard critique sur cette solution largement employée dans le milieu bancaire notamment.\nCet article a initialement été publié sur Medium.\n","permalink":"https://alainnicolas.fr/fr/blog/r3-corda-presentation/","tags":["Corda","R3","DLT"],"title":"R3 Corda : Presentation"},{"categories":null,"contents":" Découverte de Corda, le DLT développé apr le consortium R3 et qui se prend pour une blockchain. À tort ou à raison ?\n","permalink":"https://alainnicolas.fr/fr/series/corda/","tags":null,"title":"Corda"},{"categories":null,"contents":" Une nouvelle fois Talan Labs a accueilli l’Asseth pour son meetup du jeudi 28 février. Au programme : 2 présentations pour une soirée bien remplie !\nCryptoBooks : l’édition transparente Jean-René Krasucki et Thibault Verbiest présentaient leur création : une application permettant d’acheter des livres en Ether, mais aussi en une vingtaine de tokens ERC20. Partant du principe que le milieu de l’édition a tout d’une \u0026#34;boîte noire\u0026#34;, ils ont créé une ÐApp qui rend transparente la répartition du prix d’achat d’un livre entre les différents acteurs (éditeurs, auteur, ayant-droits, illustrateurs, etc.).\nLes premières ventes vont bientôt avoir lieu, rendez-vous sur CryptoBooks.club !\nDAI : présentation d’un stablecoin Rémi Foult présentait le stablecoin DAI, créé par la plateforme MakerDAO. Si des doutes existent sur l’existence d’un collatéral pour Tether, DAI propose une plus grande transparence et surtout une résilience plus importante quant à sa capacité à ne pas fluctuer et surtout à toujours garantir sa valeur réelle.\nLa vidéo du meetup La vidéo du meetup est disponible sur YouTube :\n","permalink":"https://alainnicolas.fr/fr/blog/asseth-meetup-fevrier/","tags":["Meetup","Asseth","Blockchain"],"title":"Meetup Asseth : CryptoBooks \u0026 DAI"},{"categories":null,"contents":" Le mercredi 17 octobre 2018, Talan Labs accueillait un meetup de l’Asseth dans les locaux de Talan. L’Asseth est une association organisant notamment des meetups, connus comme étant l’un des rassemblements les plus importants autour de la blockchain Ethereum en France.\nLes speakers 50 blockchainers ont fait le déplacement pour profiter de la présence de Philippe Honigman et Nicolas Danjean, fondateurs de la startup Tribute. Tribute a pour but d’aider les organisations au sens large (associations, entreprises, etc.) à développer leur réseau de contributeurs, notamment via des systèmes de récompenses et d’incentives.\nLes sujets Deux speakers pour deux talks. Tout d’abord, une présentation de la notion de token contributif, puis une plongée plus en détails dans ILOT, l’outil d’event sourcing à la base de la plateforme développée par Tribute.\nTokens contributifs Les tokens contributifs présentés par Tribute permettent de récompenser les contributeurs d’un projet, mais aussi et surtout ils sont personnalisables en fonction des projets et des organisations qui les utilisent. Ces tokens peuvent représenter des paiements futurs, ou un poids dans les décisions à venir, une part des profits à venir…​\nPhilippe Honigman\rILOT, event sourcing et action semantics ILOT, \u0026#34;I Love Organizing Things\u0026#34;, est un outil de développement qui permet de définir la sémantique des inputs et la nature des outputs. Cette logique a été portée sur Solidity, y compris le builder même de cette logique.\nNicolas Danjean\rLa vidéo des présentations Retrouvez les 2 présentations de la soirée :\nTokens contributifs, par Philippe Honigman\nILOT, outil de développement basé sur l’event sourcing et l’action semantics, par Nicolas Danjean\n","permalink":"https://alainnicolas.fr/fr/blog/meetup-lasseth-recoit-tribute/","tags":["Meetup","Asseth","Blockchain"],"title":"Meetup - L'Asseth reçoit Tribute"},{"categories":null,"contents":" Vendredi 19 janvier 2018 avait lieu le meetup de l’Asseth (Association Ethereum française), sponsorisé et hébergé par Talan Labs. Il s’agit de l’un des rassemblements les plus importants autour de la blockchain en France.\nAu programme de la soirée : une présentation du projet Colony par Aron Fischer.\nLe speaker Aron Fischer\rPlus de 70 « blockchainers » se sont déplacés pour profiter de la présence d’Aron Fischer, core dev Ethereum. Docteur en mathématiques (université de New York), Aron Fischer contribue à Casper et surtout à Swarm, le système de partage de fichiers décentralisé de la fondation Ethereum.\nLe sujet La soirée a commencé par l’annonce de la grande conférence EthCC organisée par l’Asseth : 3 jours de talks, conférences et retours d’expérience qui auront lieu en mars.\nTalan Labs sera évidemment sur place et on y présentera d’ailleurs un de nos projets !\nLe sujet principal était la présentation du projet Colony. Plateforme basée sur la blockchain et destinée aux organisations ‘open’, Colony entend bien révolutionner la manière de prendre des décisions au sein d’un groupe de travail.\nObjectif de Colony Son objectif est clair et ambitieux : permettre la création d’entreprises auto-organisées via le code plutôt que la paperasse. Mais sa cible dépasse les entreprises, en s’adressant aussi aux associations à but non lucratif ou aux projets communautaires.\nDepuis quelques jours le code source du projet est disponible et avec un peu de chance, le projet ne devrait pas trop tarder à être livré sur le réseau principal d’Ethereum.\nOrganisation d’une colonie Dans une colonie, on choisit ses tâches, qui rapportent des tokens propres à la colonie, ainsi que de la crédibilité. Cette crédibilité permet de peser dans les décisions prises par la communauté, tout en garantissant la légitimité de chacun : il faut avoir fait ses preuves pour être influent, et pas seulement parler plus fort que les autres…​\nLa vidéo de la présentation Toutes les grandes fonctionnalités de Colony ont été abordées par Aron Fischer dans un talk dense que vous pouvez retrouver dans la vidéo de l’événement :\n","permalink":"https://alainnicolas.fr/fr/blog/meetup-asseth-janvier/","tags":["Meetup","Asseth","Blockchain"],"title":"Meetup Asseth chez Talan : présentation de Colony"},{"categories":null,"contents":" A l’heure où tout le monde parle de blockchain, peut-être vous êtes-vous intéressés à l’aspect technique du développement sur Ethereum. Et peut-être vous êtes-vous dits que c’était compliqué…​ Des technologies très nouvelles, peu de documentation à jour, peu d’outils à disposition…​\nMais ça, c’était avant ! Il y a au moins un outil qui sort du lot : Truffle. Framework de développement sur Ethereum créé par Consensys, il se présente tout simplement comme le couteau suisse Ethereum. Truffle permet de compiler du Solidity (le langage des smart contracts Ethereum), tester des smart contracts, les déployer, gérer différents environnements…​\nAu travers du projet Talan Coin évoqué dans l’article que je lui ai dédié, nous avons été amenés à utiliser Truffle. Depuis le début du projet, Truffle a régulièrement été mis à jour, parfois de manière brutale…​ Mais une jolie nouveauté a vu le jour : Ganache. S’il vous reste un peu d’appétit après les truffes de Noël et la galette des rois, faites comme nous : goûtez à Ganache !\nLa recette du successeur de TestRPC est simple : une fois téléchargé, il suffit d’installer ce petit outil, et vous voilà en possession d’une blockchain personnelle légère. Au lancement, une interface claire : 10 comptes créés et alimentés de 100 ETH pour faire vos premières transactions …​ et déployer vos smart contracts.\nAperçu de l\u0026#39;interface principale de Ganache\rOn accède en un clic à la liste des blocs déjà minés, mais aussi à la liste des transactions passées et les logs (similaires à ceux de TestRPC). Deux options quant au minage : automatique à chaque transaction, ou continu avec une durée de génération de bloc fixée pour se rapprocher des conditions réelles.\nAccessible par défaut sur le port 7545 (paramétrable), il est évidemment possible de communiquer avec la blockchain en une requête cURL classique :\n$ curl 127.0.0.1:7545 -X POST \\ --data \u0026#39;{\u0026#34;jsonrpc\u0026#34;:\u0026#34;2.0\u0026#34;,\u0026#34;method\u0026#34;:\u0026#34;eth_sendTransaction\u0026#34;,\u0026#34;params\u0026#34;:[{ \u0026#34;from\u0026#34;: \u0026#34;0x627306090abaB3A6e1400e9345bC60c78a8BEf57\u0026#34;, \u0026#34;to\u0026#34;: \u0026#34;0xf17f52151EbEF6C7334FAD080c5704D77216b732\u0026#34;, \u0026#34;gas\u0026#34;: \u0026#34;0x76c0\u0026#34;, \u0026#34;gasPrice\u0026#34;: \u0026#34;0x9184e72a000\u0026#34;,\u0026#34;value\u0026#34;: \u0026#34;0x9184e72a\u0026#34;}],\u0026#34;id\u0026#34;:1}\u0026#39; --:--:-- {\u0026#34;id\u0026#34;:1,\u0026#34;jsonrpc\u0026#34;:\u0026#34;2.0\u0026#34;,\u0026#34;result\u0026#34;:\u0026#34;0x873cc520a53026128d021aa05d47b9e1b2bc7825d876a95ea68b7cb466fd06df\u0026#34;} La clarté de l’interface, la capacité d’explorer les blocs un par un, et même les transactions qu’ils contiennent en font un outil parfait de test et de débug au cours du développement d’un smart contract, facilitant indéniablement le travail des aventuriers de la blockchain.\nLe projet Truffle est régulièrement mis à jour, parfois de manière brutale et non rétrocompatible, il en sera peut-être ainsi pour Ganache…​ Il n’en reste pas moins que l’effort de clarté et d’UX au service du développeur en font un incontournable du milieu Ethereum, désormais recommandé au sein de Talan Labs.\n","permalink":"https://alainnicolas.fr/fr/blog/presentation-ganache/","tags":["Développement","Ganache","Ethereum","Blockchain"],"title":"Présentation de Ganache"},{"categories":null,"contents":" Google a annoncé le 23 février 2017 avoir réussi à casser la fonction de « hachage » SHA-1. Il s’agit là d’un événement majeur affectant la sécurité de nombreux systèmes allant de la signature de documents aux certificats de sécurité d’un site internet.\nQu’est-ce que la fonction de « hachage » SHA-1 ? SHA-1 (Secure Hash Algorithm) est une fonction de « hachage » cryptographique.\nIl s’agit d’un algorithme qui associe à une donnée de taille quelconque, une image de taille fixe. En quelque sorte, une empreinte de la donnée d’entrée. Le calcul de cette empreinte est à sens unique : il est possible de calculer l’empreinte d’une donnée, mais pas de retrouver la donnée depuis l’empreinte. Cela signifie donc qu’il est impossible de revenir en arrière une fois la donnée hachée. De plus, une fonction de hachage doit assigner UNE empreinte unique : 2 données d’entrée ne peuvent pas avoir la même empreinte.\nC’est ainsi qu’un message « haché » par SHA-1 change radicalement de signature, même avec une modification mineure. Par exemple le mot \u0026#34;TalanLabs\u0026#34; devient 499dfc6db8ca1f785724cd88ffef5f471e874156 une fois « haché ». En revanche, \u0026#34;Talanlabs\u0026#34; devient 25f51e7cbd92b575adf321cc3b149e76d48e2431.\nSHA-1 a été conçue par la puissante NSA, autrement dit l’agence nationale de la sécurité des États-Unis, en remplacement de SHA-0 (sortie en 1993) qui était compromise.\nQu’est-il arrivé à SHA-1 ? Depuis sa sortie en 1995, de nombreux chercheurs ont tenté de compromettre SHA-1, a minima dans des démonstrations mathématiques. C’est ainsi que depuis 2005, nous savons qu’il est en théorie possible d’obtenir une même empreinte pour 2 données différentes en réalisant 263 calculs (soit plus de 9 milliards de milliards…​). Ce nombre astronomique d’opérations est encore à la limite des capacités des super-ordinateurs actuels. Il semblerait que seul un immense réseau distribué à l’échelle mondiale (à l’image du réseau Bitcoin) soit capable de délivrer suffisamment de puissance de calcul pour obtenir une « collision » (deux données d’entrée différentes avec la même empreinte).\nÀ titre de comparaison, il faudrait environ 12 millions de GPU (puces graphiques) qui fonctionneraient pendant un an pour obtenir cette même « collision ».\nJusqu’alors, nous ne disposions que de données théoriques, et jamais de cas pratiques. C’est finalement fin février qu’une équipe composée de chercheurs de Google et du CWI (centre de recherche en mathématiques et informatiques néerlandais) a annoncé avoir trouvé une « collision » entre 2 fichiers PDF qui ont la même signature une fois « hachés » par SHA-1.\nIllustration d\u0026#39;une collision\rMême avec les moyens considérables de Google, il n’était pas questions d’aligner des millions de cartes graphiques pour réaliser une telle prouesse. En affinant les calculs théoriques, et en éliminant d’office certains calculs, l’équipe a eu besoin que de 6 500 années CPU (soit 6 500 processeurs pendant un an) ou 110 années GPU (soit 110 cartes graphiques pendant un an) pour obtenir deux documents PDF différents mais avec la même signature.\nQuelles sont les conséquences de la « collision » de SHA-1 ? Concrètement, l’outil mis au point permet d’obtenir un faux document qui sera identifié comme un vrai document. Autrement dit de faire passer une donnée potentiellement biaisée comme purement véridique et approuvée par son émetteur.\nAlors, quels sont les systèmes potentiellement rendus vulnérables ? Tous ceux qui utilisent SHA-1 comme algorithme de « hachage » pour certifier leurs données…​ Et ils sont nombreux ! SHA-1 est utilisé pour certifier une connexion HTTPS, signer numériquement des documents, authentifier les informations contenues dans un système de sauvegarde (cloud par exemple), mais aussi par un outil de gestion de versions comme Git.\nSystèmes impactés\rGit, outil privilégié pour la gestion des versions du code source de millions de projets informatiques, utilise SHA-1 pour identifier de manière unique chaque « commit » (modification) de code. Autrement dit, lorsque vous récupérez le code source d’un projet, la version que vous téléchargez est identifiée par un « hash » unique certifiant le contenu. Or, si du code malveillant a été injecté par la suite, mais avec une signature de « commit » identique à la dernière en date, nul système ne pourra le détecter et vous vous exposez à des failles de sécurité.\nAutrement dit, sans le savoir nous utilisons tous les jours des algorithmes de « hachage », et la sécurité de nos données et de nos entreprises est fortement liée à leur qualité. Une remise en cause totale de nos habitudes est-elle encore envisageable ? Revenir exclusivement aux signatures sur papier, aux messagers humains et à la sauvegarde centralisée ?\nQuelles alternatives à SHA-1 ? Heureusement, des alternatives sont possibles. Et la responsabilité en incombe en grande partie aux développeurs, mais aussi aux décisionnaires de toutes les entreprises liées au numérique.\nSHA-1 n’est pas la seule fonction disponible. bcrypt (présentée en 1999), SHA-2 (conçue par elle aussi par la NSA en 2001) et plus récemment SHA-3 (issue d’une compétition en 2012) n’ont pas été compromises. Même si l’on peut imaginer qu’il ne s’agit là encore que d’une question de temps…​\nRecommandations de Google \u0026amp; CWI\rGoogle et le CWI ne cherchant évidemment pas à compromettre massivement les réseaux mondiaux, ils ont émis une recommandation simple : utiliser SHA-2 ou SHA-3 partout. De plus, ils ont attendu 90 jours avant de rendre publique la méthode utilisée pour arriver à leurs fins, afin de laisser le temps à l’industrie de se mettre à jour. De leur côté, ils garantissent que leurs produits comme Gmail ou Google Drive sont d’ores et déjà protégés. Par ailleurs, leur navigateur Chrome ne considère plus les certificats HTTPS basés sur SHA-1 comme sécurisés.\nIls fournissent de surcroit un outil en ligne permettant de vérifier si un document fait partie d’une attaque par « collision » ainsi qu’une infographie de référence qui mériterait d’être affichée dans de nombreuses DSI.\n","permalink":"https://alainnicolas.fr/fr/blog/collision-sha-1-securite/","tags":["Google","Sécurité"],"title":"Collision SHA-1 et sécurité"},{"categories":null,"contents":" Les mises à jour successives de Windows apportent de la sécurité et parfois de nouvelles fonctionnalités. Globalement, elles apportent une meilleure expérience pour l’utilisateur, rarement des retours en arrière.\nWindows 10 se met à jour automatiquement mais introduit de la publicité dans le navigateur Le système de mise à jour a lui aussi été modifié avec le passage à Windows 10, puisqu’il est désormais plus contrôlable par l’utilisateur (les mises à jour se font d’elles-mêmes).\nEt c’est désormais officiel, Microsoft a intégré la publicité au sein de son explorateur de fichiers. Autrement dit, lorsque vous naviguez dans le contenu de votre PC, vous pouvez rencontrer de la publicité. Actuellement centrée sur l’outil OneDrive (stockage dans le cloud développé par Microsoft), nous pouvons craindre que cette fonctionnalité intéresse très vite les agences publicitaires, en leur offrant un nouveau terrain de jeu.\nPublicité dans l\u0026#39;explorateur de fichiers Windows\rAlors, pour ou contre la publicité au sein même de votre ordinateur ?\nLa question ne se pose pas trop, disons-le ! Un ordinateur coûte cher, un système d’exploitation comme Windows aussi. Nul doute que dans un contexte professionnel il est difficile d’imaginer des publicités intrusives à ce point. Et quid des lois définissant l’abus de position dominante ?\nComment supprimer la publicité dans votre navigateur Windows Heureusement, la solution de contournement existe déjà, ici en anglais !\nEn résumé (et en français) :\nAller dans l’onglet \u0026#34;Affichage \u0026#34;de l’Explorateur de fichiers\nSélectionner \u0026#34;Option\u0026#34;\nSélectionner \u0026#34;Modifier le dossier et les options de recherche\u0026#34;\nAller dans l’onglet \u0026#34;Affichage\u0026#34; de cette nouvelle fenêtre\nDans les \u0026#34;Paramètres Avancés\u0026#34;, décocher \u0026#34;Afficher les notifications du fournisseur de synchronisation\u0026#34;\n","permalink":"https://alainnicolas.fr/fr/blog/windows-10-publicite-explorateur/","tags":["Microsoft","Windows"],"title":"Windows 10 : de la publicité dans l'explorateur"},{"categories":null,"contents":" Tous les développeurs le savent, leur métier ne consiste pas juste à produire du code, mais plus globalement à penser un système, imaginer des algorithmes ou réfléchir à l’intégration de leur projet dans un cadre plus vaste, tout en prenant en compte les besoins réels du client, le ressenti des utilisateurs et des budgets parfois serrés.\nL’état de concentration nécessaire pour être efficace, créatif et apporter les meilleures réponses possibles aux problèmes soulevés fait du développement un métier à part entière, loin de l’image véhiculée par les médias ou même Tim Cook (CEO d’Apple) qui considère que c’est \u0026#34;marrant et interactif\u0026#34;.\nOn donne parfois un nom à cette concentration intense : le « flow ». Cet état est bien connu des sportifs ou des musiciens mais il ne faut pas ignorer que dans certaines conditions le travail peut aussi permettre d’atteindre la \u0026#34;Zone\u0026#34; du flow.\nEn effet, pour arriver à un tel état, un ensemble de paramètres est nécessaire :\nDes objectifs clairement définis\nUn retour d’informations instantané\nUne activité en adéquation avec ses compétences\nC’est alors que l’état de « flow » peut se manifester, à travers 4 dimensions bien distinctes et référencées :\nL’absorption cognitive : sentiment de maîtrise et de contrôle de son activité (pas d’anxiété, pas d’ennui)\nL’altération de la perception du temps : concentration sur le présent, on ne voit pas le temps passer\nLa dilation de l’égo : perte de la conscience de soi, sérénité\nLe sentiment de bien-être : motivation intrinsèque, extase, sortie de la réalité quotidienne\nEt vous alors, avez-vous déjà expérimenté ce sentiment de complétude en développant ?\nMusique \u0026amp; Développement Le cliché du développeur avec le casque vissé sur les oreilles, bien que caricatural, n’en est pas moins une expression de la recherche de concentration. Le casque isole du brouhaha de l’open-space, il permet d’écouter de la musique, mais il est aussi un avertissement sur le fait que l’on ne souhaite pas être dérangé.\nJustement, au sein d’un même open-space, que trouve-t-on dans le casque des développeurs qui écoutent de la musique ? Un rapide sondage chez Talan Labs fait ressortir que tout est bon pour se concentrer : électro, podcasts, bandes originales de films / jeux vidéo, etc.\nPlaylists sur 8tracks radio\rEt lorsque l’on cherche sur internet, on trouve des dizaines, voire des centaines de « playlists » destinées aux développeurs. C’est principalement de la musique électronique, facile à écouter. On retrouve aussi de la musique classique, bref des styles musicaux propices à la concentration.\nPour autant, on trouve parfois des choix très étonnants. C’est ainsi qu’un certain Jake Denison (le genre de développeur qui travaillait pour la NASA à 15 ans) explique qu’il écoute du métal lorsqu’il code. Et ce n’est pas juste pour s’amuser, il y a de vraies explications ! Le rythme rapide permet de réfléchir plus vite, la \u0026#39;lourdeur\u0026#39; du son permet d’aller plus loin dans son état de « flow », l’agressivité générale permet de maintenir la motivation et la complexité stimulerait les connexions neuronales.\nEt vous alors, est-ce que vous écoutez de la musique en développant ? Est-ce que vos goûts détonnent dans votre open-space ?\n","permalink":"https://alainnicolas.fr/fr/blog/concentration-musique-developpement/","tags":["Développement"],"title":"Concentration, musique \u0026 développement"},{"categories":null,"contents":" Lundi 13 novembre 2017 avait lieu le meetup de l’Asseth (Association Ethereum française). Sponsorisé et hébergé par Talan Labs, il s’agit de l’un des rassemblements les plus importants autour de la blockchain en France.\nAu programme de la soirée : le débriefing de la Devcon3, la conférence annuelle des développeurs Ethereum qui avait lieu début novembre, à Cancún au Mexique.\nDevcon3 - La conférence annuelle des développeurs Ethereum\rEnviron 85 \u0026#34;blockchainers\u0026#34; se sont déplacés pour profiter des retours de Jérôme de Tychey, président de l’Asseth. En 45 minutes seulement, il a réussi à nous faire vivre 4 jours de conférence. Et quelle conférence ! Devcon3 c’est plus d’une centaine de présentations, devant 1 800 personnes venues du monde entier.\nPlus de 80 blockchainers chez @talan_fr pour le #meetup de l\u0026#39;@AssethFR ! #ethereum #devcon3 pic.twitter.com/XXk2ZpvZQf\n\u0026mdash; alainnicolas.eth/lens (@Alain_Ncls) November 13, 2017 Les sujets abordés lors de Devcon3 Il y a les incontournables, comme la désormais fameuse présentation \u0026#34;Ethereum en 25 minutes\u0026#34; de Vitalik Buterin, cofondateur d’Ethereum. Mais il y a aussi des présentations plus nouvelles, comme Sikorka, un outil qui permet de prouver sa présence physique de manière infalsifiable à travers la blockchain.\n\u0026#34;Les 3 talks qui ont marqué @jdetychey à #DevCon3 : #Sikoria pour la #ProofOfPresence, le #PackageManagement, et #MetaMask pour mettre de l\u0026#39;#Ethereum dans votre navigateur !\u0026#34; — Talan Labs (@TalanLabs) C’était aussi l’occasion de voir un point d’avancement sur les travaux visant à rendre possible l’utilisation d’Ethereum à travers des clients légers, une fonctionnalité encore inaccessible mais très demandée par les développeurs blockchain.\nEthereum est un environnement conçu par des développeurs, pour des développeurs. Et l’ergonomie de développement n’est pas au rendez-vous, loin de là. C’est ainsi que des outils comme Puppeth ont vu le jour, pour faciliter le déploiement d’une blockchain privée, et donc favoriser la démocratisation d’Ethereum sur les projets. L’outillage se fait de plus en plus complet, comme avec Remix, l’environnement de développement web pour les smart contracts.\n\u0026#34;#Geth : développer pour #Ethereum est compliqué, @puppetize peut vous faciliter la vie ! Les développeurs #Blockchain apprécient !\u0026#34; — Talan Labs (@TalanLabs) Côté langage, pas de révolution sur Solidity en 2017, le langage contract-oriented d’implémentation de smart contracts, si ce n’est que le support de _struct _comme argument de méthodes approche. Ce qui n’empêche pas les bonnes pratiques de se répandre, et les recommandations en termes de sécurité d’émerger de manière plus affirmée.\nSur le plan de la communication avec un client, l’écosystème Ethereum se renforce avec un nouveau framework JavaScript : EthJS. Après web3.js, EthereumJS ou encore parity.js, il semblerait que le consensus ne soit pas encore atteint pour élire la référence JavaScript sur Ethereum.\n\u0026#34;Après #web3js, #EthereumJS, #parityjs, voici #EthJS, le framework (de référence ?) pour le développement #Ethereum en #JavaScript\u0026#34; — Talan Labs (@TalanLabs) Échanger avec la communauté Ethereum Une fois la présentation achevée et après une dizaine de questions, il était temps de reprendre des forces autour d’un buffet.\nC’était aussi l’occasion d’échanger de manière plus informelle autour de nombreux sujets ayant trait à la blockchain, avec un public aux profils variés. Comptables, avocats, développeurs, mais aussi UX designers, Ethereum rapproche toutes les parties prenantes des projets informatiques. Et si ce n’était pas la plus grande réussite d’une technologie encore en plein essor ?\nToujours est-il que Talan Labs compte bien participer activement au mouvement qui se crée autour de la blockchain et de nouveaux événements sont à prévoir dans les prochains mois !\nDécouvrez la vidéo du meetup sur le debrief de Devcon 3 :\n","permalink":"https://alainnicolas.fr/fr/blog/meetup-asseth-devcon3-talan-ethereum/","tags":["Asseth","Blockchain","Ethereum","Meetup"],"title":"Meetup Asseth chez Talan : retour sur Devcon3"},{"categories":null,"contents":" Mardi 10 octobre 2017, Talan accueillait un « meetup » des « HumanTalks », que nous vous avions présenté il y a quelques mois.\nAu programme de la soirée : 4 « talks » de qualité sur des sujets plus ou moins techniques, un public de près de 70 personnes, principalement des développeurs, mais aussi des designers UX et des responsables des Ressources Humaines.\n1er talk : Mythes et Légendes de l’UX Présenté par Marc Wabnitz, UX designer chez Talan Labs, ce talk présentait 7 idées reçues autour de l’expérience utilisateur.\nOn dit souvent que les utilisateurs ne lisent pas ce qui est écrit sur une page web, mais c’est faux. De la même manière, on a tendance à croire qu’en copiant les géants du web comme Facebook ou Google, un site sera réussi, mais il n’en est rien.\nEn 7 points bien ciblés, Marc a su nous convaincre d’aller plus loin que certains lieux communs trop souvent associés à l’UX.\n2e talk : Le HTTPS : à quoi ça sert, comment on fait ? \u0026#34;#HumanTalks : le #HTTPS, à quoi ça sert, comment ça marche ?\u0026#34; — Talan Labs (@TalanLabs) Présenté par Foucauld Degeorges, qui après un rappel des principes cryptographiques sur lesquels repose HTTPS, nous a présenté l’intérêt d’utiliser un tel protocole sur un site internet. Il a notamment présenté des solutions gratuites et fiables pour faire du HTTPS sur un site.\n3e talk : Pour que le CSS ne soit plus une corvée Pour vous le CSS est une corvée ? En reprenant les bases et les bonnes pratiques et avec quelques bons conseils et règles de survie, Albéric Trancart a prouvé qu’il est possible d’optimiser l’utilisation du CSS de manière à rendre plus acceptable un langage trop souvent mal vu. Il y a visiblement plus efficace que d’utiliser !important à tout bout de champ…​\n4e talk : Planification de rendez-vous avec OptaPlanner Présenté par Richard Hanna. Le support, c’est par ici !\nQuand il a un problème complexe de planification de rendez-vous, Richard utilise OptaPlanner. Outil open-source capable de résoudre des problèmes complexes (ou NP-Complet), il permet d’approcher une solution considérée comme optimale.\nROTI : de la qualité avant tout ! Tradition des HumanTalks : le ROTI (Return On Time Invested) qui permet à tous de s’exprimer quant à la qualité des présentations. Une bonne manière pour les intervenants de s’améliorer.\nROTI de cette édition des HumanTalks\rLa soirée s’est achevée dans la bonne humeur autour d’un buffet, l’occasion pour chacun de nouer des liens et de permettre de nouvelles rencontres.\nPlus qu’un mois avant les prochains HumanTalks, ce sera l’occasion de fêter leurs 5 ans le 14 novembre 2017.\n\u0026#34;Bravo et merci aux speakers des @HumanTalksParis de ce soir : @alberictrancart @richardhanna @foucdeg @krowab #meetup #HumanTalks\u0026#34; — Talan Labs (@TalanLabs) ","permalink":"https://alainnicolas.fr/fr/blog/humantalks-talan/","tags":["Meetup"],"title":"Les HumanTalks chez Talan"},{"categories":null,"contents":" Les compte-rendus des meetups hébergés par Talan que j’ai eu le plaisir d’accueillir.\n","permalink":"https://alainnicolas.fr/fr/series/meetups-talan/","tags":null,"title":"Meetups chez Talan"},{"categories":null,"contents":" Présentée pour la première fois le 4 octobre au 1er Forum Parlementaire de la Blockchain, la monnaie virtuelle du groupe Talan est en passe de rentrer en phase de production. L’occasion de présenter en détails les tenants et les aboutissants d’un projet et d’une initiative pas comme les autres : Talan Coin !\nBannière Talan Coin\rLa blockchain, tout le monde en parle, depuis les médias généralistes jusqu’aux startups les plus innovantes. Et pourtant, rares sont les idées à aller jusqu’à la phase de production. C’est pourquoi Talan a souhaité se démarquer et proposer à ses collaborateurs une application réelle de cette technologie en plein essor. C’est ainsi que l’idée d’une monnaie interne est née de l’envie de fédérer le personnel d’un groupe international autour d’un modèle de partage commun.\nTalan Coin, c’est son nom, abrégé en ‘TC’, est une monnaie basée sur la blockchain, et plus particulièrement sur Ethereum. Ethereum est une blockchain largement utilisée, et sa monnaie, l’Ether, est la deuxième plus grosse capitalisation des crypto-monnaies, derrière le Bitcoin. Le principal apport d’Ethereum par rapport à Bitcoin est sa capacité à intégrer de la logique et des règles métier inaltérables puisque stockées sur la blockchain en elle-même. Il s’agit des fameux “Smart Contracts”, concept que nous développerons plus amplement dans un article à venir.\nPourquoi lancer cette monnaie ? Comme toutes les entreprises, Talan cherche à catalyser la collaboration en son sein. De plus, Talan souhaite renforcer son unité en tant que groupe malgré des entités distinctes et une répartition sur 4 continents et développer une horizontalité bien loin des hiérarchies verticales classiques. Une monnaie interne, commune à tous les collaborateurs, peu importe leur localisation ou leur rôle hiérarchique, permet de trouver un point commun entre tous les acteurs de l’entreprise. C’est aussi une manière de permettre à tous de mieux échanger, y compris entre équipes distinctes, affirmant ainsi une hiérarchie horizontale.\nAperçu du Dashboard de suivi de Talan Coin\rDe plus, en suivant l’évolution des échanges de cette monnaie et les raisons de transfert, Talan Coin permet un feedback immédiat des tendances chez Talan. L’introduction d’un volet de gamification incite par ailleurs à plus d’utilisation encore, à travers l’organisation de challenges.\nÀ quoi ressemble Talan Coin ? Aperçu de la version mobile de Talan Coin\rTalan Coin est accessible à tous les collaborateurs du groupe à travers une application mobile (iOS et Android) téléchargeable sur les stores officiels de Google et Apple. L’orientation mobile de Talan Coin garantit une adoption assez large de l’application et permet à tous d’accéder au système. Cela élimine les éventuelles restrictions de connexion pour nos collaborateurs en mission chez nos clients ou tout simplement en déplacement.\nAperçu de la version web de Talan Coin\rPar ailleurs, de manière à étendre encore la portée et l’accessibilité du produit, une version web, orientée desktop est en cours de finalisation, pour permettre une nouvelle expérience, dans tous les moments d’une journée de travail.\nEt concrètement, comment ça marche ? Il y a deux types de portefeuilles en circulation : les portefeuilles personnels pour l’ensemble des collaborateurs et les portefeuilles d’équipes, gérés par une ou plusieurs personne(s) identifiée(s) comme leader(s) sur un sujet ou d’une équipe.\nLes portefeuilles personnels peuvent échanger de l’argent avec tous les autres portefeuilles personnels, mais pas directement avec les portefeuilles équipes. Ces derniers permettent de ‘rémunérer’ les collaborateurs œuvrant au bénéfice d’une équipe.\nComment gagner des Talan Coins ? Comment gagner des TC ?\rComme nous l’avons vu précédemment, l’objectif principal de Talan Coin est de favoriser les échanges et le partage au sein de l’entreprise. C’est ainsi que toutes les actions visant à aider Talan et plus largement qui y facilitent la vie quotidienne sont susceptibles d’être récompensées en Talan Coins.\nLes axes clairement identifiés pour le moment sont les suivants :\nAider ses collègues (coup de main occasionnel, soutien technique, etc.)\nInnover (lancer un nouveau projet, une idée qui peut changer les processus internes, etc.)\nS’impliquer dans la vie du groupe (participation aux communautés, organisation de meetups, rédaction d’articles pour les blogs Talan, etc.)\nÊtre sympa (la blague du matin, l’aide spontanée, etc.)\nPartager ses connaissances (production de formations, organisation d’une présentation technique, mentoring et parrainage, etc.)\nFluidifier les process internes (participation à un appel d’offre, cooptation, etc.)\nComment donner des Talan Coins ? Comment donner des TC ?\rLa fonctionnalité de transfert est disponible depuis les applications mobiles et web. Une raison est associée à chaque transfert, afin de fournir des indicateurs d’utilisation, mais aussi dans un but de laisser une trace dans les historiques de chacun.\nCes raisons de transfert permettent aussi de créer autant de catégories de classement dans le volet ‘gamification’. Il est évidemment prévu de faire évoluer cette liste en fonction des besoins qui seront découverts.\nComment convertir ses Talan Coins ? Comment convertir ses TC ?\rUne participation active à la vie de l’entreprise permet de gagner des Talan Coins, mais encore faut-il pouvoir les utiliser, en autre via une conversion en biens ou services. C’est ainsi que Talan se repose sur 2 boutiques propres à fournir des produits ou services payables en Talan Coin.\nCampus Talan Historiquement, il s’agit de la première ‘boutique’ identifiée comme source d’offres pour Talan Coin. En effet, le Campus Talan héberge déjà l’ensemble des formations internes et externes délivrées aux collaborateurs Talan. Il paraissait donc naturel d’y ajouter de nouvelles offres de formations jusqu’alors non disponibles, pour ouvrir de nouvelles opportunités.\nIl n’est évidemment pas question de rendre payant ce qui était gratuit depuis le lancement du Campus Talan, mais bien d’étendre la portée d’un outil central au groupe Talan.\nAperçu du Campus Talan\rChaque leader d’équipe a la possibilité d’ajouter une offre dans le Campus, en spécifiant un tarif en TC, ce qui rend l’offre visible depuis les applications mobiles et web. On peut donc imaginer un collaborateur souhaitant se rendre à une formation payante jusqu’alors non prise en charge par Talan et qui ferait une demande à un leader d’équipe. Celui-ci n’aurait alors qu’à acheter une place à cette formation en € (via le processus classique), et la rendre disponible sur le Campus Talan avec un prix en TC associé. Les TC récoltés par la vente de cette offre au collaborateur reviendraient donc au portefeuille d’équipe, remboursant l’investissement en € initié.\nUn tel dispositif garantit par ailleurs que les offres de formation ne sont plus négociées au cas par cas, mais ouvertes à tous, assurant une plus grande équité et une mise à disposition de tous les collaborateurs des offres.\nTalan Coin Shop De manière à fournir des offres en plus des formations, nous avons développé une nouvelle boutique adaptée pour vendre des objets et des services. Ce ‘Talan Coin Shop’ permet de notifier l’acheteur et le vendeur du bon déroulement d’une transaction.\nAperçu du Talan Coin Shop\rLà aussi, les leaders d’équipes peuvent ajouter des offres, composées d’un titre, d’une description, d’une image et d’un prix. Lors d’un achat, le vendeur et l’acheteur sont notifiés par mail une fois la transaction bien déroulée.\nTalan Coin est une monnaie fondante Attention monnaie fondante !\rDe manière à dynamiser l’économie de Talan Coin, nous avons imaginé utiliser un principe de monnaie fondante. Le concept en est assez simple : lorsqu’un collaborateur ne dépense pas l’argent qu’il a reçu au bout d’un mois, il perd un pourcentage de la somme gagnée. Sans trop pénaliser un collaborateur qui serait en congés par exemple, la somme ponctionnée sera ainsi ré-injectée dans le système global, tout en motivant tout un chacun à utiliser, échanger ou dépenser ses Talan Coins.\nEn effet, pour nous, l’un des indicateurs clés de la réussite du projet Talan Coin réside tout simplement dans le nombre de transactions qui auront lieu au jour le jour. Cela indiquerait ainsi l’adoption de la monnaie dans la vie quotidienne de l’entreprise.\nLa suite…​ La réalisation d’un tel projet, résolument novateur, n’a pas été sans embûche, ni sans découvertes et enseignements de toutes sortes. Nous tenons à partager notre expérience et nos connaissances nouvelles avec le plus grand nombre, ne serait-ce qu’au regard de l’aide apportée par la communauté de plus en plus importante de développeurs Ethereum.\n\u0026gt;\u0026gt;\u0026gt; Le site officiel Talan Coin \u0026lt;\u0026lt;\u0026lt;\n","permalink":"https://alainnicolas.fr/fr/blog/quest-ce-que-talancoin/","tags":["Blockchain","Ethereum"],"title":"Qu’est-ce que Talan Coin ?"},{"categories":null,"contents":" Parmi les nombreux frameworks JavaScript, AngularJS est indéniablement celui qui a connu le plus de succès. Mis en ligne en 2010 et avec une première version publiée en 2012, Angular n’a eu de cesse de s’améliorer avec une communauté croissante, des besoins qui évoluent et une équipe de développement soutenue par Google. Et puis l’an dernier, tout a changé…​\nAncien logo d\u0026#39;AngularJS\rAngularJS devient Angular 2 Nouveau logo d\u0026#39;Angular 2\rLes annonces autour de la nouvelle version majeure d’AngularJS, désormais appelée Angular 2, surprennent. C’est en fait un nouveau framework qui se profile, une nouvelle approche, une nouvelle manière de penser. Et évidemment cette nouvelle version n’est pas rétro-compatible avec la précédente…​ Nous n’entrerons pas ici dans les détails qui ont poussé l’équipe a totalement ré-écrire le framework, mais une chose est sûre, un projet en AngularJS n’est pas directement transposable en Angular 2 sans un effort de développement, voire parfois une remise à zéro du projet. Ce qui n’est pas sans poser des problèmes.\nPas de version 3 pour Angular La sortie de la première version officielle d’Angular 2 date seulement du 14 septembre 2016, et à peine remis de nos émotions, nous apprenons en décembre qu’une nouvelle version majeure va voir le jour. Angular 3 donc ? Encore un changement radical, une perte de la capitalisation de connaissances, une remise en question totale et un changement de paradigme ? Non. Et non.\nEn fait, il va s’agir d’Angular 4. Oui oui, on oublie la version 3. En réalité, il y a déjà une version 3, puisque le module \u0026#39;router\u0026#39; est en 3.x depuis quelque temps. De manière à éviter toute confusion (notamment dans les paquets NPM), la nouvelle version du framework sera la version 4.\nCode Angular 2\rPromesse de l’équipe de développement : cette fois-ci il n’y aura pas de breaking changes, la nouvelle version sera rétrocompatible avec la 2. C’est une promesse, reste à voir si elle va être tenue ! Pour le moment, les premières versions bêta (4.0.0-beta.4 au 19 janvier 2017) laissent supposer que les changements sont en effet de l’ordre de la mise à jour et de l’optimisation, mais pas de la ré-écriture complète. Plutôt rassurant…​\nAngular : bilan de la version 4 S’il est bien entendu encore trop tôt pour juger de l’adhésion de la communauté à cette nouvelle version prévue en mars prochain, il est certain que certains points ne peuvent pas être ignorés. Le changement majeur entre AngularJS et la version 2, revenant à en faire deux frameworks totalement différents ne contribue-t-il pas à créer une forme de défiance des clients finaux, frileux à l’idée d’intégrer un framework capable de changer du tout au tout en quelques mois ?\nEt maintenant que l’on parle d’une nouvelle version majeure, sera-t-il réellement aisé de convaincre les décideurs du bien-fondé d’une telle démarche de mise à jour ? Si l’on sait déjà que les changements de version correspondent à de réelles améliorations visant à rendre l’outil toujours plus robuste et adapté aux usages actuels, il n’en reste pas moins nécessaire de garder en tête les conséquences en termes de marketing et d’adhésion de la communauté.\nIllustration de la numérotation des versions\rCe qui est certain pour le moment, c’est que le planning des prochaines versions d’Angular est d’ores et déjà en place :\nLes patchs seront publiés toutes les semaines\nDes versions mineures* seront publiées tous les mois\nLes versions majeures* (et rétro-compatibles) seront publiées tous les 6 mois, soit :\nAngular 4 - Mars 2017\nAngular 5 - Octobre 2017\nAngular 6 - Mars 2018\nAngular 7 - Octobre 2018\nÀ noter que les deux frameworks AngularJS et Angular 2 ont chacun un site et une documentation, bien séparés : angularjs.org pour AngularJS et angular.io pour Angular 2+.\n","permalink":"https://alainnicolas.fr/fr/blog/oubliez-angular-3-voici-angular-4/","tags":["Développement","JavaScript","Angular","Google"],"title":"Oubliez Angular 3, voici la version 4"},{"categories":null,"contents":" Résumé des épisodes précédents…​\nDepuis plusieurs mois la communauté Java est en émoi. Oracle semble se désintéresser de Java EE. Au terme d’une saga résumée en novembre, c’est finalement lors de la grande conférence annuelle JavaOne que l’entreprise annonce une nouvelle feuille de route pour Java EE, ainsi que le lancement d’un sondage visant à mieux cerner les aspirations et attentes de la communauté.\nPrésentation du sondage Oracle Nous l’évoquions : Oracle tente de se réconcilier avec la communauté Java, tout en faisant avancer ses travaux sur Java EE. L’entreprise californienne est passée par un sondage pour mieux comprendre ses utilisateurs, mais aussi pour valider les choix déjà faits. Après 2 mois, ce sont 1693 personnes qui ont soumis leurs réponses. Il est intéressant de noter que la France semble ne pas avoir beaucoup répondu au formulaire comme l’illustre la carte de l’Europe des réponses fournie par Oracle dans son rapport exhaustif…​\nRéponses au sondage en Europe\rDe manière à mieux décrire les participants au sondage, Oracle y fait figurer leurs années d’expérience. Et avec près de 50 % des sondés ayant plus de 8 ans d’expérience en Java EE, nous pouvons raisonnablement considérer que ceux-ci possèdent le recul nécessaire à une bonne maîtrise de l’environnement. De plus, avec plus de la moitié des participants ayant déjà développé des micro-services, le sondage reflète la réalité du travail des développeurs de l’écosystème Java actuel.\nLes résultats du sondage Java EE En demandant de noter de 1 (Pas important) à 5 (Très important) les différentes technologies envisagées pour la prochaine version de Java EE, Oracle comptait obtenir un graphe à la lecture aisée et simple, et l’objectif semble atteint avec ce classement :\nRésultats du sondage\rOn note donc que (sans trop de surprises) les services REST, la prise en charge de HTTP/2 et la gestion des protocoles OAuth et OpenID sont plébiscités par la communauté pour intégrer Java EE au plus vite. Ce résultat n’est pas une surprise dans la mesure où cela colle réellement aux projets actuels, avec des API fournissant des données parfois pour plusieurs applications différentes, ainsi que la \u0026#39;mode\u0026#39; des microservices.\nDe plus, l’attente d’une standardisation des configurations d’applications et la gestion des événements soulignent la dimension croissante des déploiements d’application Java dans le cloud.\nEn revanche, l’API JMS par exemple semble avoir fait son temps, et la communauté ne voit pas son évolution comme une priorité absolue. De même, un framework standard d’interface web n’est pas nécessaire, dans la mesure où les nouvelles applications ont tendance à se doter d’interfaces web basées sur des frameworks JavaScript.\nLes conclusions d’Oracle pour Java EE 8 Dans un article de blog, Oracle annonce ses conclusions suite à ce sondage. Et force est de constater que l’avis de la communauté est réellement pris en compte et va influer sur la suite du développement de Java EE 8. En effet, pour satisfaire la demande sur l’évolution de REST, JAX-RS va passer en version 2.1, une servlet 4.0 va voir le jour pour épouser HTTP/2.\nConclusions d\u0026#39;Oracle suite au sondage\rLes protocoles d’authentification OAuth et OpenID vont avoir des standards en Java EE (mais normalement pas en version 8). De la même manière, dans la mesure où l’intégration de \u0026#39;Configuration\u0026#39; et \u0026#39;Health Checking\u0026#39; risquerait de retarder la sortie de cette version, ces éléments devraient être introduits \u0026#39;plus tard\u0026#39;. Quant à Management, JMS et MVC …​ ils sont retirés de Java EE 8.\nEn résumé, Oracle semble réellement avoir pris en compte les avis de sa communauté et modifie sa feuille de route, ce qui parait rassurant. Reste maintenant à voir la sortie de Java EE 8 de manière effective, ainsi que la suite des événements. En effet, avec une telle prise en compte des opinions et une grande réactivité, la communauté peut être rassurée, au moins en attendant les premières annonces relatives à Java EE 9 !\n","permalink":"https://alainnicolas.fr/fr/blog/resultats-sondage-java-ee/","tags":["Développement","Java"],"title":"Java EE, nouvelle orientation : les résultats du sondage"},{"categories":null,"contents":" Parce que la vie d’un développeur ce n’est pas qu’un quotidien routinier face à un écran rempli de code, il est parfois important d’élargir ses idées et de se confronter au travail et aux passions d’autres acteurs de la communauté. C’est ainsi que je vous propose aujourd’hui de découvrir un meetup, les Human Talks.\nMais au fait, qu’est-ce qu’un meetup ?\nQu’est-ce qu’un meetup ? Logo Meetup.com\rC’est avant tout un événement de réseautage, autour d’un intérêt commun. Il en existe dans tous les domaines, comme le sport, les langues ou l’engagement politique, dans le monde entier. En effet, le site Meetup.com, qui fait office de référence mondiale, recense plus de 23 millions d’utilisateurs dans 180 pays. Quels que soient vos centres d’intérêt, vous êtes obligés de trouver votre bonheur parmi leurs plus de 200 000 groupes.\nÉvénements incontournables au sein des communautés de développeurs, les meetups permettent de rencontrer ses pairs, de lier de nouvelles relations, mais aussi de découvrir des nouvelles technologies, voire des domaines jusqu’alors inconnus. Bref, les meetups ouvrent l’esprit et étendent notre champ de réflexion, facilitant une veille technologique pas toujours aisée avec un emploi à plein temps.\nLe meetup des Human Talks J’ai personnellement participé à une douzaine de meetups en un peu plus d’un an, en grande partie aux Human Talks de Paris qui fêtaient leurs 4 ans en novembre. Initiés par Human Coders, centre de formation visant à favoriser les échanges entre développeurs, les Human Talks sont une série de 4 talks (ou présentations) de 10 minutes chacun, se déroulant une fois par mois et hébergés par des entreprises du numérique (Viadeo, Dailymotion, Prestashop,…​).\nLes sujets sont présentés principalement par des développeurs et pour des développeurs, avec des thèmes aussi larges que la programmation, les retours d’expérience, les méthodes de travail…​ Et il n’y a pas que Paris, puisque les Human Talks sont aussi présents à Lyon, Toulouse, Nancy, pour un total de 14 villes.\nLes 4 ans des Human Talks à Paris Pour leur anniversaire, les Human Talks ont fait les choses en grand ! Avec comme hôte Google France et leurs locaux assez grandioses, ce sont plus de 250 personnes qui se sont retrouvées pour 4 présentations :\nGraphQL, the new age of API ?\nwww : The Web Will Win\nTout ce que vous pensez savoir sur la couleur est faux\nHacker-Dev API on the Way\nDes sujets techniques donc, mais aussi de quoi découvrir un nouveau domaine comme le bug bounty, ou réaliser que les écrans que nous utilisons n’affichent pas toutes les couleurs visibles à l’œil nu. Et après une ultime présentation bonus sur la prise de parole en public, il était temps de tous se retrouver autour de pizzas, bières et cupcakes d’anniversaire, pour débriefer, échanger et rencontrer des développeurs de tous horizons.\nEt vous alors, quand est-ce que l’on vous croise à un meetup ?\n","permalink":"https://alainnicolas.fr/fr/blog/presentation-meetup-human-talks/","tags":["Meetup"],"title":"Présentation d''un meetup : les Human Talks"},{"categories":null,"contents":" Peut-être que pour vous la série de l’été 2016 était Stranger Things, mais dans le vaste monde du Java, une toute autre série aux multiples rebondissements a retenu toutes les attentions. Rachat, rébellion et sondages, plongeon dans la révolution de Java EE !\n","permalink":"https://alainnicolas.fr/fr/series/java-ee-nouvelle-orientation/","tags":null,"title":"Java EE : nouvelle orientation"},{"categories":null,"contents":" Peut-être que pour vous la série de l’été était Stranger Things, la petite pépite aux couleurs années 80-90 de Netflix. Mais dans le vaste monde du Java, une toute autre série aux multiples rebondissements a retenu toutes les attentions.\nPour introduire le récit de cet été de toutes les surprises, un petit historique s’impose…​\nJava, Sun et Oracle L’entreprise Sun est fondée en 1982, et lance Java en 1995. Un programme en Java peut s’exécuter tel quel (ou presque) sur toutes les plateformes (Windows, UNIX, etc.), est plus sécurisé qu’en C++, adapté à la programmation distribuée, supporte le multi-threading, etc. Très vite, Java prend son essor, pour toutes ses caractéristiques, révolutionnaires pour l’époque.\nLogo Java EE\rLa spécification de Java, ‘orientée entreprise’, J2EE 1.2, sort en 1999 et continue d’évoluer jusqu’à la version Java EE 7 publiée en 2013. Mais entre temps, Oracle a racheté Sun. Pour rappel, Oracle c’est 110 milliards de chiffre d’affaires, et des produits ultra-répandus comme Oracle Database ou Weblogic.\nLes craintes de la communauté Open Source sont vite confirmées, Oracle abandonnant par exemple le développement d’OpenSolaris (un système d’exploitation de Sun). L’open n’est pas la priorité d’Oracle, et l’on commence à craindre pour Java. Le procès intenté par Oracle à Google pour son utilisation de Java dans Android laisse à penser que le monde du Java va se refermer sur lui-même et que sa communauté va se réduire. En mai 2016, la Cour Suprême des États-Unis se prononce en faveur de Google, jugeant que son utilisation de Java est licite.\nJava EE Guardians Au mois de juin 2016, James Gosling, qui n’est rien de moins que le créateur de Java, s’émeut du manque d’intérêt évident d’Oracle pour Java EE et rejoint les Java EE Guardians, un groupement de décideurs, de développeurs, de “users’ groups” et d’entreprises de premier ordre. Leur revendication est simple : ils souhaitent plus de transparence de la part d’Oracle, et l’assurance de la continuation des travaux sur Java EE (8 et plus).\nLogo Java EE Guardians\rLes hostilités sont ouvertes. La communauté fourmille d’idées pour assurer la survie de Java EE, allant jusqu’à proposer le transfert de son support à IBM ou Red Hat.\nAprès une période de mutisme, Oracle réagit en juillet. C’est par la voix de son président du développement produit, Thomas Kurian, que l’entreprise affiche son ambition de moderniser cette spécification pour applications professionnelles. L’annonce reste vague et ne convainc pas vraiment.\nUne semaine plus tard, Oracle communique de nouveau sur Java EE 8, en expliquant que cette version sera équipée pour le déploiement dans le cloud, adaptée aux microservices et au multi-tenant (la capacité d’une application à servir plusieurs organisations clientes). Encore une fois, et même si l’effet d’annonce est plus important, les Guardians demandent des détails…​\nLa feuille de route C’est finalement à l’occasion de sa conférence JavaOne 2016, la grande messe du Java, qu’Oracle fait ses annonces les plus intéressantes, et les plus détaillées. Du 18 au 22 septembre, les conférences et ateliers techniques s’enchaînent, avec cette année un accent fort sur le futur de Java.\nJavaOne\rDans sa volonté de se réconcilier avec la communauté qui se sentait bafouée, Oracle lance une vaste campagne de sondage visant à recueillir les attentes de tout un chacun. Les résultats ne sont pas encore publics, mais nul doute que l’initiative a de quoi rassurer. Oracle compte bien écouter la communauté.\nQuant à la feuille de route : après le report de la publication de Java 9 (prévue pour 2016) à juillet 2017, Java EE 8 est attendu pour la première moitié de 2017. Et, surprise, pour rattraper le décalage entre les versions de Java EE et Java, une version 9 est prévue dès 2018.\nJava EE Roadmap\rDeux versions de Java EE en un an, ce serait inédit, et non sans laisser imaginer de nouveaux problèmes. Quel intérêt aurait une entreprise à migrer ses projets de Java EE 7 à 8 puis, immédiatement ensuite à relancer un chantier pour passer à la version 9 ?\nLa suite…​ La réorientation stratégique des objectifs de Java EE vers des problématiques très actuelles (micro-services, cloud, etc.), les échéances resserrées et toutes ces annonces en quelques mois seulement ne sont pas sans soulever de nombreuses questions. Et en réalité non sans laisser planer de nombreuses incertitudes…​\nAlors, bonnes ou mauvaises nouvelles ? Bonnes ou mauvaises décisions ? Il est bien entendu encore trop tôt pour le dire. Mais ce qui est certain, c’est que seule la communauté des développeurs pourra réellement faire de cette nouvelle version une réussite ou un échec, un engouement ou un désenchantement.\n","permalink":"https://alainnicolas.fr/fr/blog/java-ee-nouvelle-orientation-bonne-nouvelle/","tags":["Développement","Java"],"title":"Java EE, nouvelle orientation : une bonne nouvelle ?"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/android/","tags":null,"title":"Android"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/angular/","tags":null,"title":"Angular"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/asciidoc/","tags":null,"title":"AsciiDoc"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/asseth/","tags":null,"title":"Asseth"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/azure-devops/","tags":null,"title":"Azure DevOps"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/bitcoin/","tags":null,"title":"Bitcoin"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/blockchain/","tags":null,"title":"Blockchain"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/blogging/","tags":null,"title":"Blogging"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/corda/","tags":null,"title":"Corda"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/cycle-en-v/","tags":null,"title":"Cycle en V"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/developpement/","tags":null,"title":"Développement"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/dlt/","tags":null,"title":"DLT"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/docker/","tags":null,"title":"Docker"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/epf/","tags":null,"title":"EPF"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/ethereum/","tags":null,"title":"Ethereum"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/formation/","tags":null,"title":"Formation"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/ganache/","tags":null,"title":"Ganache"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/git/","tags":null,"title":"Git"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/github/","tags":null,"title":"GitHub"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/gitlab/","tags":null,"title":"GitLab"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/google/","tags":null,"title":"Google"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/gradle/","tags":null,"title":"Gradle"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/hugo/","tags":null,"title":"Hugo"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/hyperledger-fabric/","tags":null,"title":"Hyperledger Fabric"},{"categories":null,"contents":"Insights.io est un concurrent de Google Analytics, qui a la particularité d\u0026rsquo;être beaucoup moins invasif quant à la confidentialité des visiteurs des sites qui en sont équipés.\nEn ne déposant pas de cookie, il récupère moins d\u0026rsquo;informations, tout en conservant ce qui compte réellement : quelles pages sont visitées, pendant combien de temps, etc. Cet outil permet donc de se passer des bannières \u0026ldquo;consentement cookies\u0026rdquo; qui détériorent souvent un peu trop notre expérience du web.\nPour récolter ses informations, Insights.io repose sur une librairie JavaScript éditée par les créateurs du service. Je me suis permis d\u0026rsquo;en créer un fork qui filtre les robots et autres visiteurs que l\u0026rsquo;on ne souhaite pas comptabiliser dans les statistiques finales.\n","permalink":"https://alainnicolas.fr/fr/tags/insights/","tags":null,"title":"Insights"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/intellij-idea/","tags":null,"title":"IntelliJ IDEA"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/ios/","tags":null,"title":"iOS"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/java/","tags":null,"title":"Java"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/java-swing/","tags":null,"title":"Java Swing"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/javascript/","tags":null,"title":"JavaScript"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/jira/","tags":null,"title":"Jira"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/jquery/","tags":null,"title":"jQuery"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/jsp/","tags":null,"title":"JSP"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/kanban/","tags":null,"title":"Kanban"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/linux/","tags":null,"title":"Linux"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/macos/","tags":null,"title":"macOS"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/markdown/","tags":null,"title":"Markdown"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/maven/","tags":null,"title":"Maven"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/meetup/","tags":null,"title":"Meetup"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/microsoft/","tags":null,"title":"Microsoft"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/mongodb/","tags":null,"title":"MongoDB"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/mysql/","tags":null,"title":"mySQL"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/nestjs/","tags":null,"title":"NestJS"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/nodejs/","tags":null,"title":"Node.js"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/npm/","tags":null,"title":"NPM"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/oracledb/","tags":null,"title":"OracleDB"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/perso/","tags":null,"title":"Perso"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/quorum/","tags":null,"title":"Quorum"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/r3/","tags":null,"title":"R3"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/react/","tags":null,"title":"React"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/rgpd/","tags":null,"title":"RGPD"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/scrum/","tags":null,"title":"Scrum"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml\n[outputs] home = [\u0026#34;HTML\u0026#34;, \u0026#34;JSON\u0026#34;] Searching additional files To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category\n... \u0026#34;contents\u0026#34;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026#34;tags\u0026#34;:{{ .Params.tags | jsonify }}{{end}}, \u0026#34;categories\u0026#34; : {{ .Params.categories | jsonify }}, ... Edit fuse.js options to Search static/js/search.js\nkeys: [ \u0026#34;title\u0026#34;, \u0026#34;contents\u0026#34;, \u0026#34;tags\u0026#34;, \u0026#34;categories\u0026#34; ] ","permalink":"https://alainnicolas.fr/fr/search/","tags":null,"title":"Search"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/securite/","tags":null,"title":"Sécurité"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/solidity/","tags":null,"title":"Solidity"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/sonarqube/","tags":null,"title":"SonarQube"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/spring-boot/","tags":null,"title":"Spring Boot"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/spring-mvc/","tags":null,"title":"Spring MVC"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/spring-rest-docs/","tags":null,"title":"Spring REST Docs"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/tarteaucitron/","tags":null,"title":"Tarteaucitron"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/truffle/","tags":null,"title":"Truffle"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/typescript/","tags":null,"title":"TypeScript"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/vault/","tags":null,"title":"Vault"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/vuejs/","tags":null,"title":"Vue.js"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/windows/","tags":null,"title":"Windows"},{"categories":null,"contents":"","permalink":"https://alainnicolas.fr/fr/tags/wordpress/","tags":null,"title":"WordPress"}]